{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717cc3c0",
   "metadata": {},
   "source": [
    "## Scenario 2: building a model trained on both stream gauges and HWMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533d0b5e",
   "metadata": {},
   "source": [
    "### a) Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4426e360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e645a45",
   "metadata": {},
   "source": [
    "### b) Reading the stream gauges and HWM data for hurricane Ida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09fc780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df_HWM = pd.read_csv('HWMs.csv', header=0)\n",
    "df_HWM['Mean_Gage_height']= 0\n",
    "df_HWM['Type'] = 'HWMs'\n",
    "\n",
    "df_strm = pd.read_csv('Ida.csv', header=0)\n",
    "df_strm['HAND']=0\n",
    "df_strm['Distance to river']=0\n",
    "df_strm['Flood']= df_strm['Max_Gage_height']-df_strm['Mean_Gage_height']\n",
    "df_strm['Type'] = 'Stream'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e5182",
   "metadata": {},
   "source": [
    "### c) Combining stream gauge and HWM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356a4019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>HAND</th>\n",
       "      <th>Storm surge</th>\n",
       "      <th>Wind speed</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Soil moisture</th>\n",
       "      <th>Flow accumulation</th>\n",
       "      <th>TWI</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Distance to river</th>\n",
       "      <th>Distance to storm track</th>\n",
       "      <th>Mean_Gage_height</th>\n",
       "      <th>Distance to sea</th>\n",
       "      <th>Type</th>\n",
       "      <th>Flood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.929120e+09</td>\n",
       "      <td>7.37162</td>\n",
       "      <td>8.89971</td>\n",
       "      <td>0.772498</td>\n",
       "      <td>34.5617</td>\n",
       "      <td>0.044960</td>\n",
       "      <td>0.392925</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.933630</td>\n",
       "      <td>2.002040</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.391555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073790</td>\n",
       "      <td>HWMs</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.667340e+09</td>\n",
       "      <td>7.37162</td>\n",
       "      <td>8.74236</td>\n",
       "      <td>0.772498</td>\n",
       "      <td>34.5617</td>\n",
       "      <td>0.044960</td>\n",
       "      <td>0.392925</td>\n",
       "      <td>51</td>\n",
       "      <td>-2.421870</td>\n",
       "      <td>3.105190</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.391619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073833</td>\n",
       "      <td>HWMs</td>\n",
       "      <td>3.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.007710e+08</td>\n",
       "      <td>3.46794</td>\n",
       "      <td>3.46790</td>\n",
       "      <td>2.017150</td>\n",
       "      <td>33.5172</td>\n",
       "      <td>0.124228</td>\n",
       "      <td>0.331936</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.200457</td>\n",
       "      <td>0.168553</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.489294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062434</td>\n",
       "      <td>HWMs</td>\n",
       "      <td>1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.010870e+09</td>\n",
       "      <td>3.74653</td>\n",
       "      <td>3.87530</td>\n",
       "      <td>1.589750</td>\n",
       "      <td>33.7572</td>\n",
       "      <td>0.119348</td>\n",
       "      <td>0.331936</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.989910</td>\n",
       "      <td>0.286747</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.419288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133445</td>\n",
       "      <td>HWMs</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.526490e+09</td>\n",
       "      <td>5.20485</td>\n",
       "      <td>5.68098</td>\n",
       "      <td>0.772498</td>\n",
       "      <td>34.5617</td>\n",
       "      <td>0.044960</td>\n",
       "      <td>0.392925</td>\n",
       "      <td>68759</td>\n",
       "      <td>6.244250</td>\n",
       "      <td>0.708235</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.393270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074235</td>\n",
       "      <td>HWMs</td>\n",
       "      <td>1.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>9.700830e+09</td>\n",
       "      <td>315.74000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.282130</td>\n",
       "      <td>31.5753</td>\n",
       "      <td>1.533940</td>\n",
       "      <td>0.279366</td>\n",
       "      <td>2592720</td>\n",
       "      <td>16.286273</td>\n",
       "      <td>12.305600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985841</td>\n",
       "      <td>3.757292</td>\n",
       "      <td>0.370593</td>\n",
       "      <td>Stream</td>\n",
       "      <td>2.502708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>3.441800e+08</td>\n",
       "      <td>270.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.296930</td>\n",
       "      <td>31.9977</td>\n",
       "      <td>1.286300</td>\n",
       "      <td>0.352202</td>\n",
       "      <td>2924290</td>\n",
       "      <td>18.546203</td>\n",
       "      <td>1.420260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>2.472708</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>Stream</td>\n",
       "      <td>5.177292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>-1.934700e+09</td>\n",
       "      <td>331.84000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.275670</td>\n",
       "      <td>31.7314</td>\n",
       "      <td>1.619680</td>\n",
       "      <td>0.258539</td>\n",
       "      <td>552958</td>\n",
       "      <td>15.547339</td>\n",
       "      <td>5.531940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916809</td>\n",
       "      <td>2.266146</td>\n",
       "      <td>0.303099</td>\n",
       "      <td>Stream</td>\n",
       "      <td>2.503854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>-8.706530e+09</td>\n",
       "      <td>586.60000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.337360</td>\n",
       "      <td>30.7331</td>\n",
       "      <td>0.494721</td>\n",
       "      <td>0.381326</td>\n",
       "      <td>369281</td>\n",
       "      <td>14.192663</td>\n",
       "      <td>14.157900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100598</td>\n",
       "      <td>1.503437</td>\n",
       "      <td>0.481995</td>\n",
       "      <td>Stream</td>\n",
       "      <td>2.766563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>8.392130e+09</td>\n",
       "      <td>539.63000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.313270</td>\n",
       "      <td>31.4692</td>\n",
       "      <td>0.787706</td>\n",
       "      <td>0.381326</td>\n",
       "      <td>137751</td>\n",
       "      <td>14.476887</td>\n",
       "      <td>4.009810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086518</td>\n",
       "      <td>1.303229</td>\n",
       "      <td>0.470245</td>\n",
       "      <td>Stream</td>\n",
       "      <td>2.536771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Curvature   Altitude     HAND  Storm surge  Wind speed      Rain  \\\n",
       "0   -1.929120e+09    7.37162  8.89971     0.772498     34.5617  0.044960   \n",
       "1   -5.667340e+09    7.37162  8.74236     0.772498     34.5617  0.044960   \n",
       "2   -5.007710e+08    3.46794  3.46790     2.017150     33.5172  0.124228   \n",
       "3    1.010870e+09    3.74653  3.87530     1.589750     33.7572  0.119348   \n",
       "4    1.526490e+09    5.20485  5.68098     0.772498     34.5617  0.044960   \n",
       "..            ...        ...      ...          ...         ...       ...   \n",
       "366  9.700830e+09  315.74000  0.00000     1.282130     31.5753  1.533940   \n",
       "367  3.441800e+08  270.50000  0.00000     1.296930     31.9977  1.286300   \n",
       "368 -1.934700e+09  331.84000  0.00000     1.275670     31.7314  1.619680   \n",
       "369 -8.706530e+09  586.60000  0.00000     1.337360     30.7331  0.494721   \n",
       "370  8.392130e+09  539.63000  0.00000     1.313270     31.4692  0.787706   \n",
       "\n",
       "     Soil moisture  Flow accumulation        TWI      Slope  \\\n",
       "0         0.392925                  0  -5.933630   2.002040   \n",
       "1         0.392925                 51  -2.421870   3.105190   \n",
       "2         0.331936                 25  -0.200457   0.168553   \n",
       "3         0.331936                  0  -3.989910   0.286747   \n",
       "4         0.392925              68759   6.244250   0.708235   \n",
       "..             ...                ...        ...        ...   \n",
       "366       0.279366            2592720  16.286273  12.305600   \n",
       "367       0.352202            2924290  18.546203   1.420260   \n",
       "368       0.258539             552958  15.547339   5.531940   \n",
       "369       0.381326             369281  14.192663  14.157900   \n",
       "370       0.381326             137751  14.476887   4.009810   \n",
       "\n",
       "     Distance to river  Distance to storm track  Mean_Gage_height  \\\n",
       "0             0.000736                 0.391555          0.000000   \n",
       "1             0.000719                 0.391619          0.000000   \n",
       "2             0.015490                 0.489294          0.000000   \n",
       "3             0.000391                 0.419288          0.000000   \n",
       "4             0.000027                 0.393270          0.000000   \n",
       "..                 ...                      ...               ...   \n",
       "366           0.000000                 0.985841          3.757292   \n",
       "367           0.000000                 0.974283          2.472708   \n",
       "368           0.000000                 0.916809          2.266146   \n",
       "369           0.000000                 1.100598          1.503437   \n",
       "370           0.000000                 1.086518          1.303229   \n",
       "\n",
       "     Distance to sea    Type     Flood  \n",
       "0           0.073790    HWMs  2.050000  \n",
       "1           0.073833    HWMs  3.920000  \n",
       "2           0.062434    HWMs  1.700000  \n",
       "3           0.133445    HWMs  2.300000  \n",
       "4           0.074235    HWMs  1.890000  \n",
       "..               ...     ...       ...  \n",
       "366         0.370593  Stream  2.502708  \n",
       "367         0.360568  Stream  5.177292  \n",
       "368         0.303099  Stream  2.503854  \n",
       "369         0.481995  Stream  2.766563  \n",
       "370         0.470245  Stream  2.536771  \n",
       "\n",
       "[371 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_columns= [\n",
    "    'Curvature',\n",
    "    'Altitude', \n",
    "    'HAND', \n",
    "    'Storm surge', \n",
    "    'Wind speed', \n",
    "    'Rain',\n",
    "    'Soil moisture', \n",
    "    'Flow accumulation', \n",
    "    'TWI', \n",
    "    'Slope',\n",
    "    'Distance to river',\n",
    "    'Distance to storm track', \n",
    "    'Mean_Gage_height',\n",
    "    'Distance to sea',\n",
    "    'Type',\n",
    "    'Flood'   \n",
    "]\n",
    "\n",
    "# Select common columns from both DataFrames\n",
    "df_HWM_common = df_HWM[common_columns]\n",
    "df_strm_common = df_strm[common_columns]\n",
    "\n",
    "\n",
    "# Concatenate DataFrames\n",
    "df = pd.concat([df_HWM_common, df_strm_common], ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('stream-hwm.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f44ceb",
   "metadata": {},
   "source": [
    "### d) Defining features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8441ed7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "features= [\n",
    "    'Curvature',\n",
    "    'Altitude', \n",
    "    'HAND', \n",
    "    'Storm surge', \n",
    "    'Wind speed', \n",
    "    'Rain',\n",
    "    'Soil moisture', \n",
    " #   'Flow accumulation', \n",
    " #   'TWI', \n",
    "    'Slope',\n",
    "    'Distance to river',\n",
    "    'Distance to storm track', \n",
    "    'Mean_Gage_height',\n",
    "    'Distance to sea' \n",
    "]\n",
    "x = df[features].copy()\n",
    "\n",
    "\n",
    "y = df['Flood']* 0.3048  #ft to m\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458de25",
   "metadata": {},
   "source": [
    "### e) Splitting and scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d691c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(x, y, test_size=0.2, random_state=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccea520",
   "metadata": {},
   "source": [
    "### f) Creating a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb6ee0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                208       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,553\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "5/5 [==============================] - 1s 47ms/step - loss: 2.0450 - val_loss: 1.9571\n",
      "Epoch 2/2000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8239 - val_loss: 1.7914\n",
      "Epoch 3/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.6537 - val_loss: 1.6079\n",
      "Epoch 4/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4959 - val_loss: 1.4760\n",
      "Epoch 5/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3669 - val_loss: 1.3725\n",
      "Epoch 6/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2703 - val_loss: 1.2855\n",
      "Epoch 7/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1793 - val_loss: 1.2261\n",
      "Epoch 8/2000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1131 - val_loss: 1.1666\n",
      "Epoch 9/2000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0297 - val_loss: 1.1276\n",
      "Epoch 10/2000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9728 - val_loss: 1.1230\n",
      "Epoch 11/2000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9475 - val_loss: 1.0792\n",
      "Epoch 12/2000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8976 - val_loss: 1.0626\n",
      "Epoch 13/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8734 - val_loss: 1.0653\n",
      "Epoch 14/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8387 - val_loss: 1.1100\n",
      "Epoch 15/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7982 - val_loss: 1.0801\n",
      "Epoch 16/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 1.0721\n",
      "Epoch 17/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7422 - val_loss: 1.0788\n",
      "Epoch 18/2000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7326 - val_loss: 1.0554\n",
      "Epoch 19/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7270 - val_loss: 1.0937\n",
      "Epoch 20/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7453 - val_loss: 1.0609\n",
      "Epoch 21/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6859 - val_loss: 1.0832\n",
      "Epoch 22/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7024 - val_loss: 1.1125\n",
      "Epoch 23/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7215 - val_loss: 1.0858\n",
      "Epoch 24/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7159 - val_loss: 1.0490\n",
      "Epoch 25/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6410 - val_loss: 1.0678\n",
      "Epoch 26/2000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6534 - val_loss: 1.0335\n",
      "Epoch 27/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6453 - val_loss: 1.0468\n",
      "Epoch 28/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6315 - val_loss: 1.1324\n",
      "Epoch 29/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5946 - val_loss: 1.1179\n",
      "Epoch 30/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6082 - val_loss: 1.1442\n",
      "Epoch 31/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5995 - val_loss: 1.1231\n",
      "Epoch 32/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5844 - val_loss: 1.0984\n",
      "Epoch 33/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5826 - val_loss: 1.0619\n",
      "Epoch 34/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6026 - val_loss: 1.0316\n",
      "Epoch 35/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6024 - val_loss: 1.0718\n",
      "Epoch 36/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5867 - val_loss: 1.0482\n",
      "Epoch 37/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5706 - val_loss: 1.0972\n",
      "Epoch 38/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5813 - val_loss: 1.0584\n",
      "Epoch 39/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5454 - val_loss: 1.0524\n",
      "Epoch 40/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5357 - val_loss: 1.0398\n",
      "Epoch 41/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5567 - val_loss: 1.0517\n",
      "Epoch 42/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5376 - val_loss: 1.0763\n",
      "Epoch 43/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5454 - val_loss: 1.0375\n",
      "Epoch 44/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5598 - val_loss: 1.0489\n",
      "Epoch 45/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5724 - val_loss: 1.0083\n",
      "Epoch 46/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5692 - val_loss: 0.9558\n",
      "Epoch 47/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5497 - val_loss: 0.9714\n",
      "Epoch 48/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5116 - val_loss: 1.0417\n",
      "Epoch 49/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5551 - val_loss: 0.9871\n",
      "Epoch 50/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5479 - val_loss: 1.0743\n",
      "Epoch 51/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5459 - val_loss: 0.9840\n",
      "Epoch 52/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5166 - val_loss: 0.9978\n",
      "Epoch 53/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5101 - val_loss: 1.0432\n",
      "Epoch 54/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5121 - val_loss: 1.0194\n",
      "Epoch 55/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5077 - val_loss: 1.0354\n",
      "Epoch 56/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5207 - val_loss: 1.0799\n",
      "Epoch 57/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5331 - val_loss: 1.0207\n",
      "Epoch 58/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5511 - val_loss: 0.9605\n",
      "Epoch 59/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5347 - val_loss: 0.9176\n",
      "Epoch 60/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5885 - val_loss: 0.8644\n",
      "Epoch 61/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5344 - val_loss: 0.8500\n",
      "Epoch 62/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5365 - val_loss: 0.8729\n",
      "Epoch 63/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5274 - val_loss: 0.8364\n",
      "Epoch 64/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5068 - val_loss: 0.8097\n",
      "Epoch 65/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5522 - val_loss: 0.8056\n",
      "Epoch 66/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5341 - val_loss: 0.8211\n",
      "Epoch 67/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5079 - val_loss: 0.8332\n",
      "Epoch 68/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4846 - val_loss: 0.8673\n",
      "Epoch 69/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5021 - val_loss: 0.8330\n",
      "Epoch 70/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4923 - val_loss: 0.8408\n",
      "Epoch 71/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5034 - val_loss: 0.8381\n",
      "Epoch 72/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4579 - val_loss: 0.8385\n",
      "Epoch 73/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4859 - val_loss: 0.8199\n",
      "Epoch 74/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4828 - val_loss: 0.7793\n",
      "Epoch 75/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4961 - val_loss: 0.7765\n",
      "Epoch 76/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4766 - val_loss: 0.7706\n",
      "Epoch 77/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4749 - val_loss: 0.7695\n",
      "Epoch 78/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4807 - val_loss: 0.8309\n",
      "Epoch 79/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4887 - val_loss: 0.8025\n",
      "Epoch 80/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5007 - val_loss: 0.8012\n",
      "Epoch 81/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5017 - val_loss: 0.7773\n",
      "Epoch 82/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4729 - val_loss: 0.7646\n",
      "Epoch 83/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4522 - val_loss: 0.7734\n",
      "Epoch 84/2000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4633 - val_loss: 0.7530\n",
      "Epoch 85/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4591 - val_loss: 0.7546\n",
      "Epoch 86/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4698 - val_loss: 0.7711\n",
      "Epoch 87/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4445 - val_loss: 0.7660\n",
      "Epoch 88/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4848 - val_loss: 0.7765\n",
      "Epoch 89/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4660 - val_loss: 0.7654\n",
      "Epoch 90/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4720 - val_loss: 0.8097\n",
      "Epoch 91/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4512 - val_loss: 0.7966\n",
      "Epoch 92/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4764 - val_loss: 0.8044\n",
      "Epoch 93/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4781 - val_loss: 0.8063\n",
      "Epoch 94/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4400 - val_loss: 0.8040\n",
      "Epoch 95/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4412 - val_loss: 0.7883\n",
      "Epoch 96/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4595 - val_loss: 0.7893\n",
      "Epoch 97/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4403 - val_loss: 0.7732\n",
      "Epoch 98/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4455 - val_loss: 0.7641\n",
      "Epoch 99/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4548 - val_loss: 0.7668\n",
      "Epoch 100/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4528 - val_loss: 0.7534\n",
      "Epoch 101/2000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5019 - val_loss: 0.7370\n",
      "Epoch 102/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4691 - val_loss: 0.7570\n",
      "Epoch 103/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4792 - val_loss: 0.7757\n",
      "Epoch 104/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4585 - val_loss: 0.7648\n",
      "Epoch 105/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4806 - val_loss: 0.7576\n",
      "Epoch 106/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4672 - val_loss: 0.7523\n",
      "Epoch 107/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4444 - val_loss: 0.7625\n",
      "Epoch 108/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4836 - val_loss: 0.7479\n",
      "Epoch 109/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4255 - val_loss: 0.7037\n",
      "Epoch 110/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4270 - val_loss: 0.6786\n",
      "Epoch 111/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4475 - val_loss: 0.6922\n",
      "Epoch 112/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4446 - val_loss: 0.7172\n",
      "Epoch 113/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4427 - val_loss: 0.7450\n",
      "Epoch 114/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4214 - val_loss: 0.7087\n",
      "Epoch 115/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4148 - val_loss: 0.7160\n",
      "Epoch 116/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4129 - val_loss: 0.7195\n",
      "Epoch 117/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4117 - val_loss: 0.7152\n",
      "Epoch 118/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4388 - val_loss: 0.6875\n",
      "Epoch 119/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4086 - val_loss: 0.6858\n",
      "Epoch 120/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4060 - val_loss: 0.7073\n",
      "Epoch 121/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4171 - val_loss: 0.6975\n",
      "Epoch 122/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4226 - val_loss: 0.7057\n",
      "Epoch 123/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4174 - val_loss: 0.7503\n",
      "Epoch 124/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4100 - val_loss: 0.7813\n",
      "Epoch 125/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4270 - val_loss: 0.8891\n",
      "Epoch 126/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4484 - val_loss: 0.8276\n",
      "Epoch 127/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4311 - val_loss: 0.8255\n",
      "Epoch 128/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4260 - val_loss: 0.8700\n",
      "Epoch 129/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4017 - val_loss: 0.8251\n",
      "Epoch 130/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4051 - val_loss: 0.7710\n",
      "Epoch 131/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4165 - val_loss: 0.7795\n",
      "Epoch 132/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4163 - val_loss: 0.8052\n",
      "Epoch 133/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3893 - val_loss: 0.8032\n",
      "Epoch 134/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4239 - val_loss: 0.7941\n",
      "Epoch 135/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4314 - val_loss: 0.7702\n",
      "Epoch 136/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4111 - val_loss: 0.7826\n",
      "Epoch 137/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3943 - val_loss: 0.7888\n",
      "Epoch 138/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3680 - val_loss: 0.7901\n",
      "Epoch 139/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4509 - val_loss: 0.7918\n",
      "Epoch 140/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4113 - val_loss: 0.7279\n",
      "Epoch 141/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4262 - val_loss: 0.6984\n",
      "Epoch 142/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3804 - val_loss: 0.7399\n",
      "Epoch 143/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4077 - val_loss: 0.7823\n",
      "Epoch 144/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4147 - val_loss: 0.8361\n",
      "Epoch 145/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4014 - val_loss: 0.7663\n",
      "Epoch 146/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3930 - val_loss: 0.7388\n",
      "Epoch 147/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4466 - val_loss: 0.7359\n",
      "Epoch 148/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4169 - val_loss: 0.7475\n",
      "Epoch 149/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4091 - val_loss: 0.7778\n",
      "Epoch 150/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4120 - val_loss: 0.8030\n",
      "Epoch 151/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3952 - val_loss: 0.8590\n",
      "Epoch 152/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3917 - val_loss: 0.7902\n",
      "Epoch 153/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4028 - val_loss: 0.7582\n",
      "Epoch 154/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3613 - val_loss: 0.7020\n",
      "Epoch 155/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3816 - val_loss: 0.6592\n",
      "Epoch 156/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3783 - val_loss: 0.6842\n",
      "Epoch 157/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3993 - val_loss: 0.7598\n",
      "Epoch 158/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4271 - val_loss: 0.8086\n",
      "Epoch 159/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3928 - val_loss: 0.8311\n",
      "Epoch 160/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3760 - val_loss: 0.8746\n",
      "Epoch 161/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3943 - val_loss: 0.8056\n",
      "Epoch 162/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3869 - val_loss: 0.7380\n",
      "Epoch 163/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3899 - val_loss: 0.6089\n",
      "Epoch 164/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4047 - val_loss: 0.6415\n",
      "Epoch 165/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3605 - val_loss: 0.6722\n",
      "Epoch 166/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3902 - val_loss: 0.6747\n",
      "Epoch 167/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3764 - val_loss: 0.6418\n",
      "Epoch 168/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3919 - val_loss: 0.6299\n",
      "Epoch 169/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3688 - val_loss: 0.6416\n",
      "Epoch 170/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3856 - val_loss: 0.6197\n",
      "Epoch 171/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3908 - val_loss: 0.5881\n",
      "Epoch 172/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3914 - val_loss: 0.5849\n",
      "Epoch 173/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3990 - val_loss: 0.5822\n",
      "Epoch 174/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3928 - val_loss: 0.6302\n",
      "Epoch 175/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3755 - val_loss: 0.6650\n",
      "Epoch 176/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3836 - val_loss: 0.5633\n",
      "Epoch 177/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3973 - val_loss: 0.5307\n",
      "Epoch 178/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3950 - val_loss: 0.5786\n",
      "Epoch 179/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3866 - val_loss: 0.6374\n",
      "Epoch 180/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3557 - val_loss: 0.5882\n",
      "Epoch 181/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3845 - val_loss: 0.5441\n",
      "Epoch 182/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3639 - val_loss: 0.5275\n",
      "Epoch 183/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3619 - val_loss: 0.5183\n",
      "Epoch 184/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3792 - val_loss: 0.5112\n",
      "Epoch 185/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3679 - val_loss: 0.5106\n",
      "Epoch 186/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3612 - val_loss: 0.5383\n",
      "Epoch 187/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3736 - val_loss: 0.5957\n",
      "Epoch 188/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3695 - val_loss: 0.5968\n",
      "Epoch 189/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3747 - val_loss: 0.6087\n",
      "Epoch 190/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3824 - val_loss: 0.6039\n",
      "Epoch 191/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3644 - val_loss: 0.5544\n",
      "Epoch 192/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3701 - val_loss: 0.5166\n",
      "Epoch 193/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3625 - val_loss: 0.5533\n",
      "Epoch 194/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3552 - val_loss: 0.5816\n",
      "Epoch 195/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3822 - val_loss: 0.5727\n",
      "Epoch 196/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3712 - val_loss: 0.5640\n",
      "Epoch 197/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3426 - val_loss: 0.5352\n",
      "Epoch 198/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3667 - val_loss: 0.5420\n",
      "Epoch 199/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3410 - val_loss: 0.5540\n",
      "Epoch 200/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3833 - val_loss: 0.6125\n",
      "Epoch 201/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3770 - val_loss: 0.5788\n",
      "Epoch 202/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3773 - val_loss: 0.4777\n",
      "Epoch 203/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3721 - val_loss: 0.4310\n",
      "Epoch 204/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3601 - val_loss: 0.4422\n",
      "Epoch 205/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3569 - val_loss: 0.4747\n",
      "Epoch 206/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3527 - val_loss: 0.4707\n",
      "Epoch 207/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4157 - val_loss: 0.4817\n",
      "Epoch 208/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3613 - val_loss: 0.4767\n",
      "Epoch 209/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3688 - val_loss: 0.5367\n",
      "Epoch 210/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3639 - val_loss: 0.5344\n",
      "Epoch 211/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3711 - val_loss: 0.5044\n",
      "Epoch 212/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3607 - val_loss: 0.4925\n",
      "Epoch 213/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3406 - val_loss: 0.4178\n",
      "Epoch 214/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3560 - val_loss: 0.4315\n",
      "Epoch 215/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3601 - val_loss: 0.4539\n",
      "Epoch 216/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3436 - val_loss: 0.4542\n",
      "Epoch 217/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3679 - val_loss: 0.4523\n",
      "Epoch 218/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3676 - val_loss: 0.4565\n",
      "Epoch 219/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3683 - val_loss: 0.4425\n",
      "Epoch 220/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3714 - val_loss: 0.4661\n",
      "Epoch 221/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3798 - val_loss: 0.4821\n",
      "Epoch 222/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3576 - val_loss: 0.4578\n",
      "Epoch 223/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3461 - val_loss: 0.4502\n",
      "Epoch 224/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3767 - val_loss: 0.4598\n",
      "Epoch 225/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3379 - val_loss: 0.4616\n",
      "Epoch 226/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3263 - val_loss: 0.5067\n",
      "Epoch 227/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2978 - val_loss: 0.4981\n",
      "Epoch 228/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3196 - val_loss: 0.4939\n",
      "Epoch 229/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3514 - val_loss: 0.5163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3571 - val_loss: 0.5330\n",
      "Epoch 231/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3434 - val_loss: 0.4925\n",
      "Epoch 232/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3288 - val_loss: 0.4717\n",
      "Epoch 233/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3588 - val_loss: 0.4801\n",
      "Epoch 234/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3330 - val_loss: 0.4838\n",
      "Epoch 235/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3680 - val_loss: 0.5774\n",
      "Epoch 236/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3206 - val_loss: 0.6074\n",
      "Epoch 237/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3379 - val_loss: 0.5782\n",
      "Epoch 238/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3426 - val_loss: 0.5280\n",
      "Epoch 239/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3654 - val_loss: 0.4880\n",
      "Epoch 240/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3339 - val_loss: 0.4568\n",
      "Epoch 241/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3408 - val_loss: 0.4595\n",
      "Epoch 242/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3380 - val_loss: 0.4854\n",
      "Epoch 243/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3326 - val_loss: 0.5100\n",
      "Epoch 244/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3061 - val_loss: 0.4832\n",
      "Epoch 245/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3285 - val_loss: 0.4772\n",
      "Epoch 246/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3379 - val_loss: 0.4524\n",
      "Epoch 247/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3264 - val_loss: 0.4378\n",
      "Epoch 248/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3266 - val_loss: 0.4796\n",
      "Epoch 249/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3822 - val_loss: 0.5140\n",
      "Epoch 250/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3258 - val_loss: 0.5389\n",
      "Epoch 251/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3410 - val_loss: 0.5505\n",
      "Epoch 252/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3159 - val_loss: 0.5592\n",
      "Epoch 253/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3575 - val_loss: 0.4969\n",
      "Epoch 254/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3576 - val_loss: 0.4455\n",
      "Epoch 255/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3488 - val_loss: 0.4387\n",
      "Epoch 256/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3772 - val_loss: 0.4590\n",
      "Epoch 257/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3724 - val_loss: 0.4447\n",
      "Epoch 258/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3418 - val_loss: 0.4485\n",
      "Epoch 259/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3334 - val_loss: 0.4583\n",
      "Epoch 260/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3109 - val_loss: 0.4562\n",
      "Epoch 261/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3368 - val_loss: 0.4522\n",
      "Epoch 262/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3423 - val_loss: 0.4811\n",
      "Epoch 263/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3185 - val_loss: 0.4916\n",
      "Epoch 264/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3374 - val_loss: 0.5031\n",
      "Epoch 265/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3045 - val_loss: 0.4952\n",
      "Epoch 266/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3312 - val_loss: 0.5022\n",
      "Epoch 267/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3771 - val_loss: 0.4903\n",
      "Epoch 268/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3567 - val_loss: 0.4992\n",
      "Epoch 269/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3337 - val_loss: 0.4849\n",
      "Epoch 270/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3380 - val_loss: 0.4655\n",
      "Epoch 271/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3538 - val_loss: 0.4726\n",
      "Epoch 272/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3199 - val_loss: 0.4991\n",
      "Epoch 273/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3278 - val_loss: 0.4862\n",
      "Epoch 274/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3399 - val_loss: 0.4476\n",
      "Epoch 275/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3108 - val_loss: 0.4327\n",
      "Epoch 276/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3179 - val_loss: 0.4287\n",
      "Epoch 277/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3165 - val_loss: 0.4380\n",
      "Epoch 278/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2992 - val_loss: 0.4708\n",
      "Epoch 279/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3766 - val_loss: 0.4725\n",
      "Epoch 280/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3319 - val_loss: 0.4620\n",
      "Epoch 281/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3268 - val_loss: 0.4334\n",
      "Epoch 282/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3169 - val_loss: 0.4427\n",
      "Epoch 283/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3066 - val_loss: 0.4515\n",
      "Epoch 284/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3181 - val_loss: 0.4687\n",
      "Epoch 285/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3391 - val_loss: 0.4714\n",
      "Epoch 286/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3273 - val_loss: 0.4574\n",
      "Epoch 287/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2986 - val_loss: 0.4539\n",
      "Epoch 288/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2949 - val_loss: 0.4312\n",
      "Epoch 289/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3142 - val_loss: 0.4414\n",
      "Epoch 290/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3541 - val_loss: 0.4683\n",
      "Epoch 291/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3080 - val_loss: 0.4659\n",
      "Epoch 292/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3039 - val_loss: 0.4500\n",
      "Epoch 293/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2979 - val_loss: 0.4437\n",
      "Epoch 294/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3269 - val_loss: 0.4455\n",
      "Epoch 295/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3183 - val_loss: 0.4285\n",
      "Epoch 296/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2957 - val_loss: 0.4332\n",
      "Epoch 297/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3047 - val_loss: 0.4475\n",
      "Epoch 298/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3298 - val_loss: 0.4335\n",
      "Epoch 299/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3423 - val_loss: 0.4263\n",
      "Epoch 300/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3366 - val_loss: 0.4566\n",
      "Epoch 301/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2879 - val_loss: 0.4701\n",
      "Epoch 302/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3366 - val_loss: 0.4801\n",
      "Epoch 303/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3393 - val_loss: 0.4491\n",
      "Epoch 304/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3194 - val_loss: 0.4358\n",
      "Epoch 305/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3150 - val_loss: 0.4327\n",
      "Epoch 306/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3082 - val_loss: 0.4581\n",
      "Epoch 307/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3121 - val_loss: 0.4807\n",
      "Epoch 308/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3236 - val_loss: 0.4965\n",
      "Epoch 309/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3278 - val_loss: 0.5023\n",
      "Epoch 310/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3639 - val_loss: 0.5052\n",
      "Epoch 311/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3055 - val_loss: 0.4835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3091 - val_loss: 0.4586\n",
      "Epoch 313/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3132 - val_loss: 0.4456\n",
      "Epoch 314/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3176 - val_loss: 0.4431\n",
      "Epoch 315/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3058 - val_loss: 0.4523\n",
      "Epoch 316/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3214 - val_loss: 0.4682\n",
      "Epoch 317/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3103 - val_loss: 0.4614\n",
      "Epoch 318/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3250 - val_loss: 0.4546\n",
      "Epoch 319/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3304 - val_loss: 0.4658\n",
      "Epoch 320/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2856 - val_loss: 0.4767\n",
      "Epoch 321/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3171 - val_loss: 0.4643\n",
      "Epoch 322/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.4527\n",
      "Epoch 323/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3152 - val_loss: 0.4438\n",
      "Epoch 324/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3331 - val_loss: 0.4711\n",
      "Epoch 325/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3197 - val_loss: 0.4469\n",
      "Epoch 326/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2937 - val_loss: 0.4371\n",
      "Epoch 327/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3331 - val_loss: 0.4380\n",
      "Epoch 328/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2836 - val_loss: 0.4403\n",
      "Epoch 329/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3081 - val_loss: 0.4717\n",
      "Epoch 330/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3064 - val_loss: 0.4382\n",
      "Epoch 331/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3434 - val_loss: 0.4276\n",
      "Epoch 332/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3279 - val_loss: 0.4307\n",
      "Epoch 333/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2958 - val_loss: 0.4264\n",
      "Epoch 334/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3038 - val_loss: 0.4303\n",
      "Epoch 335/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3242 - val_loss: 0.4253\n",
      "Epoch 336/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3522 - val_loss: 0.4201\n",
      "Epoch 337/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3178 - val_loss: 0.4189\n",
      "Epoch 338/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2925 - val_loss: 0.4301\n",
      "Epoch 339/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3214 - val_loss: 0.4318\n",
      "Epoch 340/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3151 - val_loss: 0.4238\n",
      "Epoch 341/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3421 - val_loss: 0.4267\n",
      "Epoch 342/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3252 - val_loss: 0.4273\n",
      "Epoch 343/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.4281\n",
      "Epoch 344/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2820 - val_loss: 0.4372\n",
      "Epoch 345/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2866 - val_loss: 0.4690\n",
      "Epoch 346/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3329 - val_loss: 0.4737\n",
      "Epoch 347/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2926 - val_loss: 0.4661\n",
      "Epoch 348/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2971 - val_loss: 0.4639\n",
      "Epoch 349/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3040 - val_loss: 0.4642\n",
      "Epoch 350/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2946 - val_loss: 0.4517\n",
      "Epoch 351/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2810 - val_loss: 0.4511\n",
      "Epoch 352/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3308 - val_loss: 0.4501\n",
      "Epoch 353/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3208 - val_loss: 0.4394\n",
      "Epoch 354/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2969 - val_loss: 0.4319\n",
      "Epoch 355/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3274 - val_loss: 0.4330\n",
      "Epoch 356/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2937 - val_loss: 0.4397\n",
      "Epoch 357/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2942 - val_loss: 0.4442\n",
      "Epoch 358/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3153 - val_loss: 0.4582\n",
      "Epoch 359/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2759 - val_loss: 0.4658\n",
      "Epoch 360/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3290 - val_loss: 0.4510\n",
      "Epoch 361/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2941 - val_loss: 0.4340\n",
      "Epoch 362/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2989 - val_loss: 0.4386\n",
      "Epoch 363/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2964 - val_loss: 0.4462\n",
      "Epoch 364/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2498 - val_loss: 0.4663\n",
      "Epoch 365/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2867 - val_loss: 0.4786\n",
      "Epoch 366/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3009 - val_loss: 0.4785\n",
      "Epoch 367/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2976 - val_loss: 0.4769\n",
      "Epoch 368/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3393 - val_loss: 0.4759\n",
      "Epoch 369/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3030 - val_loss: 0.4682\n",
      "Epoch 370/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2862 - val_loss: 0.4586\n",
      "Epoch 371/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3226 - val_loss: 0.4363\n",
      "Epoch 372/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3151 - val_loss: 0.4237\n",
      "Epoch 373/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3038 - val_loss: 0.4251\n",
      "Epoch 374/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2931 - val_loss: 0.4401\n",
      "Epoch 375/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2789 - val_loss: 0.4582\n",
      "Epoch 376/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2997 - val_loss: 0.4698\n",
      "Epoch 377/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3028 - val_loss: 0.4722\n",
      "Epoch 378/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3052 - val_loss: 0.4524\n",
      "Epoch 379/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2887 - val_loss: 0.4521\n",
      "Epoch 380/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2930 - val_loss: 0.4483\n",
      "Epoch 381/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3132 - val_loss: 0.4448\n",
      "Epoch 382/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3423 - val_loss: 0.4419\n",
      "Epoch 383/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2935 - val_loss: 0.4378\n",
      "Epoch 384/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3280 - val_loss: 0.4333\n",
      "Epoch 385/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2624 - val_loss: 0.4300\n",
      "Epoch 386/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3137 - val_loss: 0.4279\n",
      "Epoch 387/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2830 - val_loss: 0.4245\n",
      "Epoch 388/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3095 - val_loss: 0.4314\n",
      "Epoch 389/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2930 - val_loss: 0.4318\n",
      "Epoch 390/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2911 - val_loss: 0.4471\n",
      "Epoch 391/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3131 - val_loss: 0.4604\n",
      "Epoch 392/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2668 - val_loss: 0.4617\n",
      "Epoch 393/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3062 - val_loss: 0.4417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2903 - val_loss: 0.4335\n",
      "Epoch 395/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2943 - val_loss: 0.4319\n",
      "Epoch 396/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2757 - val_loss: 0.4361\n",
      "Epoch 397/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3129 - val_loss: 0.4402\n",
      "Epoch 398/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3110 - val_loss: 0.4355\n",
      "Epoch 399/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2892 - val_loss: 0.4365\n",
      "Epoch 400/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2750 - val_loss: 0.4449\n",
      "Epoch 401/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2988 - val_loss: 0.4395\n",
      "Epoch 402/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2915 - val_loss: 0.4415\n",
      "Epoch 403/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2844 - val_loss: 0.4377\n",
      "Epoch 404/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3295 - val_loss: 0.4366\n",
      "Epoch 405/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.4431\n",
      "Epoch 406/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2842 - val_loss: 0.4499\n",
      "Epoch 407/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2685 - val_loss: 0.4565\n",
      "Epoch 408/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2754 - val_loss: 0.4574\n",
      "Epoch 409/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2957 - val_loss: 0.4549\n",
      "Epoch 410/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3101 - val_loss: 0.4466\n",
      "Epoch 411/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2854 - val_loss: 0.4307\n",
      "Epoch 412/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2921 - val_loss: 0.4261\n",
      "Epoch 413/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3009 - val_loss: 0.4230\n",
      "Epoch 414/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2902 - val_loss: 0.4185\n",
      "Epoch 415/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2917 - val_loss: 0.4148\n",
      "Epoch 416/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3021 - val_loss: 0.4194\n",
      "Epoch 417/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2724 - val_loss: 0.4219\n",
      "Epoch 418/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2671 - val_loss: 0.4240\n",
      "Epoch 419/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2659 - val_loss: 0.4201\n",
      "Epoch 420/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2895 - val_loss: 0.4214\n",
      "Epoch 421/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2938 - val_loss: 0.4273\n",
      "Epoch 422/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3234 - val_loss: 0.4346\n",
      "Epoch 423/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2851 - val_loss: 0.4368\n",
      "Epoch 424/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3063 - val_loss: 0.4409\n",
      "Epoch 425/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3079 - val_loss: 0.4494\n",
      "Epoch 426/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3010 - val_loss: 0.4509\n",
      "Epoch 427/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2924 - val_loss: 0.4446\n",
      "Epoch 428/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3182 - val_loss: 0.4373\n",
      "Epoch 429/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3427 - val_loss: 0.4374\n",
      "Epoch 430/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2871 - val_loss: 0.4403\n",
      "Epoch 431/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2978 - val_loss: 0.4418\n",
      "Epoch 432/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2671 - val_loss: 0.4422\n",
      "Epoch 433/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3106 - val_loss: 0.4426\n",
      "Epoch 434/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2704 - val_loss: 0.4344\n",
      "Epoch 435/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2629 - val_loss: 0.4207\n",
      "Epoch 436/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3140 - val_loss: 0.4147\n",
      "Epoch 437/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3267 - val_loss: 0.4156\n",
      "Epoch 438/2000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3463 - val_loss: 0.4118\n",
      "Epoch 439/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3300 - val_loss: 0.4099\n",
      "Epoch 440/2000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2831 - val_loss: 0.4069\n",
      "Epoch 441/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2645 - val_loss: 0.4093\n",
      "Epoch 442/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2738 - val_loss: 0.4100\n",
      "Epoch 443/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2754 - val_loss: 0.4139\n",
      "Epoch 444/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.4195\n",
      "Epoch 445/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2945 - val_loss: 0.4244\n",
      "Epoch 446/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2969 - val_loss: 0.4309\n",
      "Epoch 447/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2595 - val_loss: 0.4318\n",
      "Epoch 448/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2861 - val_loss: 0.4284\n",
      "Epoch 449/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2728 - val_loss: 0.4212\n",
      "Epoch 450/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2976 - val_loss: 0.4165\n",
      "Epoch 451/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2717 - val_loss: 0.4152\n",
      "Epoch 452/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2757 - val_loss: 0.4133\n",
      "Epoch 453/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2868 - val_loss: 0.4091\n",
      "Epoch 454/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3127 - val_loss: 0.4093\n",
      "Epoch 455/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2828 - val_loss: 0.4162\n",
      "Epoch 456/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2907 - val_loss: 0.4236\n",
      "Epoch 457/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2871 - val_loss: 0.4313\n",
      "Epoch 458/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2874 - val_loss: 0.4341\n",
      "Epoch 459/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3116 - val_loss: 0.4310\n",
      "Epoch 460/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2793 - val_loss: 0.4323\n",
      "Epoch 461/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2985 - val_loss: 0.4312\n",
      "Epoch 462/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2741 - val_loss: 0.4332\n",
      "Epoch 463/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2917 - val_loss: 0.4360\n",
      "Epoch 464/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2798 - val_loss: 0.4318\n",
      "Epoch 465/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2741 - val_loss: 0.4281\n",
      "Epoch 466/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2718 - val_loss: 0.4212\n",
      "Epoch 467/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2910 - val_loss: 0.4200\n",
      "Epoch 468/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3085 - val_loss: 0.4214\n",
      "Epoch 469/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2830 - val_loss: 0.4281\n",
      "Epoch 470/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2728 - val_loss: 0.4340\n",
      "Epoch 471/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2854 - val_loss: 0.4319\n",
      "Epoch 472/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2667 - val_loss: 0.4294\n",
      "Epoch 473/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2764 - val_loss: 0.4261\n",
      "Epoch 474/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2744 - val_loss: 0.4234\n",
      "Epoch 475/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3018 - val_loss: 0.4248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2780 - val_loss: 0.4253\n",
      "Epoch 477/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3141 - val_loss: 0.4202\n",
      "Epoch 478/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2884 - val_loss: 0.4219\n",
      "Epoch 479/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3179 - val_loss: 0.4239\n",
      "Epoch 480/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2831 - val_loss: 0.4234\n",
      "Epoch 481/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2845 - val_loss: 0.4192\n",
      "Epoch 482/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2718 - val_loss: 0.4171\n",
      "Epoch 483/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2783 - val_loss: 0.4210\n",
      "Epoch 484/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3042 - val_loss: 0.4179\n",
      "Epoch 485/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.4142\n",
      "Epoch 486/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2822 - val_loss: 0.4126\n",
      "Epoch 487/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2843 - val_loss: 0.4091\n",
      "Epoch 488/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2834 - val_loss: 0.4096\n",
      "Epoch 489/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2736 - val_loss: 0.4079\n",
      "Epoch 490/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2858 - val_loss: 0.4083\n",
      "Epoch 491/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3037 - val_loss: 0.4118\n",
      "Epoch 492/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2929 - val_loss: 0.4134\n",
      "Epoch 493/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2990 - val_loss: 0.4139\n",
      "Epoch 494/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2787 - val_loss: 0.4153\n",
      "Epoch 495/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2738 - val_loss: 0.4197\n",
      "Epoch 496/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2807 - val_loss: 0.4224\n",
      "Epoch 497/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2679 - val_loss: 0.4237\n",
      "Epoch 498/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3254 - val_loss: 0.4232\n",
      "Epoch 499/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3202 - val_loss: 0.4219\n",
      "Epoch 500/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3037 - val_loss: 0.4225\n",
      "Epoch 501/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3152 - val_loss: 0.4229\n",
      "Epoch 502/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2997 - val_loss: 0.4244\n",
      "Epoch 503/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2854 - val_loss: 0.4249\n",
      "Epoch 504/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2738 - val_loss: 0.4276\n",
      "Epoch 505/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3068 - val_loss: 0.4292\n",
      "Epoch 506/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2800 - val_loss: 0.4263\n",
      "Epoch 507/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2681 - val_loss: 0.4238\n",
      "Epoch 508/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2744 - val_loss: 0.4195\n",
      "Epoch 509/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2470 - val_loss: 0.4159\n",
      "Epoch 510/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2828 - val_loss: 0.4119\n",
      "Epoch 511/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3008 - val_loss: 0.4070\n",
      "Epoch 512/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2817 - val_loss: 0.4069\n",
      "Epoch 513/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2851 - val_loss: 0.4098\n",
      "Epoch 514/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2838 - val_loss: 0.4140\n",
      "Epoch 515/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2989 - val_loss: 0.4149\n",
      "Epoch 516/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2588 - val_loss: 0.4147\n",
      "Epoch 517/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2556 - val_loss: 0.4171\n",
      "Epoch 518/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2884 - val_loss: 0.4181\n",
      "Epoch 519/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2890 - val_loss: 0.4166\n",
      "Epoch 520/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3094 - val_loss: 0.4163\n",
      "Epoch 521/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2599 - val_loss: 0.4145\n",
      "Epoch 522/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.4118\n",
      "Epoch 523/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2946 - val_loss: 0.4115\n",
      "Epoch 524/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2718 - val_loss: 0.4141\n",
      "Epoch 525/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2858 - val_loss: 0.4118\n",
      "Epoch 526/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2552 - val_loss: 0.4111\n",
      "Epoch 527/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3633 - val_loss: 0.4141\n",
      "Epoch 528/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2929 - val_loss: 0.4195\n",
      "Epoch 529/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3041 - val_loss: 0.4197\n",
      "Epoch 530/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2766 - val_loss: 0.4204\n",
      "Epoch 531/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2775 - val_loss: 0.4175\n",
      "Epoch 532/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2744 - val_loss: 0.4149\n",
      "Epoch 533/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2680 - val_loss: 0.4158\n",
      "Epoch 534/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3106 - val_loss: 0.4168\n",
      "Epoch 535/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3115 - val_loss: 0.4218\n",
      "Epoch 536/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3188 - val_loss: 0.4228\n",
      "Epoch 537/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2761 - val_loss: 0.4233\n",
      "Epoch 538/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3146 - val_loss: 0.4217\n",
      "Epoch 539/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2919 - val_loss: 0.4169\n",
      "Epoch 540/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2589 - val_loss: 0.4139\n",
      "Epoch 541/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2791 - val_loss: 0.4140\n",
      "Epoch 542/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2783 - val_loss: 0.4144\n",
      "Epoch 543/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2422 - val_loss: 0.4147\n",
      "Epoch 544/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2819 - val_loss: 0.4157\n",
      "Epoch 545/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2507 - val_loss: 0.4169\n",
      "Epoch 546/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3002 - val_loss: 0.4176\n",
      "Epoch 547/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3036 - val_loss: 0.4224\n",
      "Epoch 548/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2949 - val_loss: 0.4250\n",
      "Epoch 549/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2619 - val_loss: 0.4251\n",
      "Epoch 550/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2714 - val_loss: 0.4223\n",
      "Epoch 551/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2501 - val_loss: 0.4186\n",
      "Epoch 552/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2607 - val_loss: 0.4164\n",
      "Epoch 553/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2590 - val_loss: 0.4143\n",
      "Epoch 554/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2740 - val_loss: 0.4131\n",
      "Epoch 555/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2874 - val_loss: 0.4120\n",
      "Epoch 556/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2921 - val_loss: 0.4114\n",
      "Epoch 557/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2698 - val_loss: 0.4116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2715 - val_loss: 0.4154\n",
      "Epoch 559/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2683 - val_loss: 0.4187\n",
      "Epoch 560/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2839 - val_loss: 0.4204\n",
      "Epoch 561/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2793 - val_loss: 0.4235\n",
      "Epoch 562/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2945 - val_loss: 0.4267\n",
      "Epoch 563/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2955 - val_loss: 0.4277\n",
      "Epoch 564/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3337 - val_loss: 0.4268\n",
      "Epoch 565/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2873 - val_loss: 0.4252\n",
      "Epoch 566/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2940 - val_loss: 0.4262\n",
      "Epoch 567/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2900 - val_loss: 0.4265\n",
      "Epoch 568/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2939 - val_loss: 0.4263\n",
      "Epoch 569/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2859 - val_loss: 0.4240\n",
      "Epoch 570/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3006 - val_loss: 0.4218\n",
      "Epoch 571/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3291 - val_loss: 0.4226\n",
      "Epoch 572/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2698 - val_loss: 0.4247\n",
      "Epoch 573/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2746 - val_loss: 0.4252\n",
      "Epoch 574/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2727 - val_loss: 0.4242\n",
      "Epoch 575/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2716 - val_loss: 0.4225\n",
      "Epoch 576/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2926 - val_loss: 0.4198\n",
      "Epoch 577/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2874 - val_loss: 0.4181\n",
      "Epoch 578/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2736 - val_loss: 0.4186\n",
      "Epoch 579/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2776 - val_loss: 0.4180\n",
      "Epoch 580/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2683 - val_loss: 0.4183\n",
      "Epoch 581/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2715 - val_loss: 0.4200\n",
      "Epoch 582/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2651 - val_loss: 0.4205\n",
      "Epoch 583/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2675 - val_loss: 0.4208\n",
      "Epoch 584/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2700 - val_loss: 0.4207\n",
      "Epoch 585/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2751 - val_loss: 0.4203\n",
      "Epoch 586/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2625 - val_loss: 0.4206\n",
      "Epoch 587/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2756 - val_loss: 0.4209\n",
      "Epoch 588/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2741 - val_loss: 0.4209\n",
      "Epoch 589/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2899 - val_loss: 0.4196\n",
      "Epoch 590/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2905 - val_loss: 0.4184\n",
      "Epoch 591/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2536 - val_loss: 0.4177\n",
      "Epoch 592/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2694 - val_loss: 0.4171\n",
      "Epoch 593/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3169 - val_loss: 0.4159\n",
      "Epoch 594/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2759 - val_loss: 0.4160\n",
      "Epoch 595/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2799 - val_loss: 0.4167\n",
      "Epoch 596/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2604 - val_loss: 0.4165\n",
      "Epoch 597/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3142 - val_loss: 0.4148\n",
      "Epoch 598/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2978 - val_loss: 0.4134\n",
      "Epoch 599/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2736 - val_loss: 0.4133\n",
      "Epoch 600/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2861 - val_loss: 0.4111\n",
      "Epoch 601/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2645 - val_loss: 0.4109\n",
      "Epoch 602/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2674 - val_loss: 0.4105\n",
      "Epoch 603/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.4097\n",
      "Epoch 604/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3016 - val_loss: 0.4089\n",
      "Epoch 605/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2797 - val_loss: 0.4087\n",
      "Epoch 606/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3109 - val_loss: 0.4090\n",
      "Epoch 607/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3123 - val_loss: 0.4101\n",
      "Epoch 608/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2791 - val_loss: 0.4095\n",
      "Epoch 609/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3038 - val_loss: 0.4080\n",
      "Epoch 610/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2908 - val_loss: 0.4084\n",
      "Epoch 611/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2539 - val_loss: 0.4082\n",
      "Epoch 612/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2799 - val_loss: 0.4088\n",
      "Epoch 613/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3062 - val_loss: 0.4095\n",
      "Epoch 614/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2765 - val_loss: 0.4098\n",
      "Epoch 615/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2880 - val_loss: 0.4099\n",
      "Epoch 616/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2878 - val_loss: 0.4096\n",
      "Epoch 617/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2862 - val_loss: 0.4097\n",
      "Epoch 618/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2679 - val_loss: 0.4096\n",
      "Epoch 619/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2722 - val_loss: 0.4098\n",
      "Epoch 620/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2934 - val_loss: 0.4104\n",
      "Epoch 621/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2722 - val_loss: 0.4108\n",
      "Epoch 622/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2997 - val_loss: 0.4119\n",
      "Epoch 623/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2545 - val_loss: 0.4136\n",
      "Epoch 624/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2761 - val_loss: 0.4152\n",
      "Epoch 625/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2651 - val_loss: 0.4167\n",
      "Epoch 626/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2728 - val_loss: 0.4184\n",
      "Epoch 627/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2714 - val_loss: 0.4191\n",
      "Epoch 628/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3238 - val_loss: 0.4184\n",
      "Epoch 629/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3006 - val_loss: 0.4177\n",
      "Epoch 630/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2642 - val_loss: 0.4159\n",
      "Epoch 631/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3118 - val_loss: 0.4146\n",
      "Epoch 632/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3197 - val_loss: 0.4137\n",
      "Epoch 633/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2785 - val_loss: 0.4129\n",
      "Epoch 634/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2596 - val_loss: 0.4126\n",
      "Epoch 635/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2576 - val_loss: 0.4132\n",
      "Epoch 636/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2688 - val_loss: 0.4148\n",
      "Epoch 637/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2663 - val_loss: 0.4150\n",
      "Epoch 638/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2976 - val_loss: 0.4151\n",
      "Epoch 639/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2716 - val_loss: 0.4159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 640/2000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2757 - val_loss: 0.4167\n",
      "Epoch 641/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2760 - val_loss: 0.4174\n",
      "Epoch 642/2000\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2804 - val_loss: 0.4170\n",
      "Epoch 643/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2433 - val_loss: 0.4163\n",
      "Epoch 644/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2688 - val_loss: 0.4160\n",
      "Epoch 645/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.4160\n",
      "Epoch 646/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2804 - val_loss: 0.4155\n",
      "Epoch 647/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2845 - val_loss: 0.4168\n",
      "Epoch 648/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2671 - val_loss: 0.4178\n",
      "Epoch 649/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2520 - val_loss: 0.4185\n",
      "Epoch 650/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2664 - val_loss: 0.4182\n",
      "Epoch 651/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2583 - val_loss: 0.4179\n",
      "Epoch 652/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3002 - val_loss: 0.4168\n",
      "Epoch 653/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2676 - val_loss: 0.4162\n",
      "Epoch 654/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2666 - val_loss: 0.4161\n",
      "Epoch 655/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2783 - val_loss: 0.4160\n",
      "Epoch 656/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2676 - val_loss: 0.4163\n",
      "Epoch 657/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3061 - val_loss: 0.4160\n",
      "Epoch 658/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2934 - val_loss: 0.4155\n",
      "Epoch 659/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2680 - val_loss: 0.4150\n",
      "Epoch 660/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2533 - val_loss: 0.4142\n",
      "Epoch 661/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2451 - val_loss: 0.4126\n",
      "Epoch 662/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2683 - val_loss: 0.4122\n",
      "Epoch 663/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2757 - val_loss: 0.4115\n",
      "Epoch 664/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2846 - val_loss: 0.4108\n",
      "Epoch 665/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2902 - val_loss: 0.4104\n",
      "Epoch 666/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2646 - val_loss: 0.4099\n",
      "Epoch 667/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3305 - val_loss: 0.4111\n",
      "Epoch 668/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2981 - val_loss: 0.4125\n",
      "Epoch 669/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3044 - val_loss: 0.4125\n",
      "Epoch 670/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2792 - val_loss: 0.4127\n",
      "Epoch 671/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3691 - val_loss: 0.4130\n",
      "Epoch 672/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2553 - val_loss: 0.4135\n",
      "Epoch 673/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2592 - val_loss: 0.4134\n",
      "Epoch 674/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3123 - val_loss: 0.4134\n",
      "Epoch 675/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2832 - val_loss: 0.4131\n",
      "Epoch 676/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2865 - val_loss: 0.4132\n",
      "Epoch 677/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2798 - val_loss: 0.4125\n",
      "Epoch 678/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2986 - val_loss: 0.4129\n",
      "Epoch 679/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2700 - val_loss: 0.4127\n",
      "Epoch 680/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2705 - val_loss: 0.4131\n",
      "Epoch 681/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2900 - val_loss: 0.4136\n",
      "Epoch 682/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2409 - val_loss: 0.4137\n",
      "Epoch 683/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2881 - val_loss: 0.4147\n",
      "Epoch 684/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2826 - val_loss: 0.4145\n",
      "Epoch 685/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2708 - val_loss: 0.4147\n",
      "Epoch 686/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2733 - val_loss: 0.4154\n",
      "Epoch 687/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2731 - val_loss: 0.4160\n",
      "Epoch 688/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2993 - val_loss: 0.4160\n",
      "Epoch 689/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2921 - val_loss: 0.4153\n",
      "Epoch 690/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2807 - val_loss: 0.4155\n",
      "Epoch 691/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2738 - val_loss: 0.4150\n",
      "Epoch 692/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2935 - val_loss: 0.4137\n",
      "Epoch 693/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2868 - val_loss: 0.4125\n",
      "Epoch 694/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2875 - val_loss: 0.4124\n",
      "Epoch 695/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2854 - val_loss: 0.4119\n",
      "Epoch 696/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2572 - val_loss: 0.4118\n",
      "Epoch 697/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3069 - val_loss: 0.4118\n",
      "Epoch 698/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2480 - val_loss: 0.4125\n",
      "Epoch 699/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2887 - val_loss: 0.4120\n",
      "Epoch 700/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2568 - val_loss: 0.4116\n",
      "Epoch 701/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3120 - val_loss: 0.4116\n",
      "Epoch 702/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2449 - val_loss: 0.4113\n",
      "Epoch 703/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2972 - val_loss: 0.4110\n",
      "Epoch 704/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2886 - val_loss: 0.4104\n",
      "Epoch 705/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2913 - val_loss: 0.4101\n",
      "Epoch 706/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2580 - val_loss: 0.4099\n",
      "Epoch 707/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2721 - val_loss: 0.4097\n",
      "Epoch 708/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2634 - val_loss: 0.4100\n",
      "Epoch 709/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2740 - val_loss: 0.4107\n",
      "Epoch 710/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2552 - val_loss: 0.4110\n",
      "Epoch 711/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2753 - val_loss: 0.4113\n",
      "Epoch 712/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2792 - val_loss: 0.4116\n",
      "Epoch 713/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2291 - val_loss: 0.4117\n",
      "Epoch 714/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2806 - val_loss: 0.4123\n",
      "Epoch 715/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2718 - val_loss: 0.4130\n",
      "Epoch 716/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3203 - val_loss: 0.4135\n",
      "Epoch 717/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2527 - val_loss: 0.4139\n",
      "Epoch 718/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2689 - val_loss: 0.4141\n",
      "Epoch 719/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2939 - val_loss: 0.4140\n",
      "Epoch 720/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2985 - val_loss: 0.4139\n",
      "Epoch 721/2000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3245 - val_loss: 0.4141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 722/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2939 - val_loss: 0.4145\n",
      "Epoch 723/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2914 - val_loss: 0.4149\n",
      "Epoch 724/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3422 - val_loss: 0.4145\n",
      "Epoch 725/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2772 - val_loss: 0.4145\n",
      "Epoch 726/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3063 - val_loss: 0.4144\n",
      "Epoch 727/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2982 - val_loss: 0.4146\n",
      "Epoch 728/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2651 - val_loss: 0.4145\n",
      "Epoch 729/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2842 - val_loss: 0.4146\n",
      "Epoch 730/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2965 - val_loss: 0.4156\n",
      "Epoch 731/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2884 - val_loss: 0.4158\n",
      "Epoch 732/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3070 - val_loss: 0.4161\n",
      "Epoch 733/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3247 - val_loss: 0.4161\n",
      "Epoch 734/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2626 - val_loss: 0.4160\n",
      "Epoch 735/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2825 - val_loss: 0.4163\n",
      "Epoch 736/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2561 - val_loss: 0.4164\n",
      "Epoch 737/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2642 - val_loss: 0.4166\n",
      "Epoch 738/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2762 - val_loss: 0.4167\n",
      "Epoch 739/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2828 - val_loss: 0.4166\n",
      "Epoch 740/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2846 - val_loss: 0.4161\n",
      "Epoch 741/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2745 - val_loss: 0.4161\n",
      "Epoch 742/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2981 - val_loss: 0.4161\n",
      "Epoch 743/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2738 - val_loss: 0.4160\n",
      "Epoch 744/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3019 - val_loss: 0.4159\n",
      "Epoch 745/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2765 - val_loss: 0.4158\n",
      "Epoch 746/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2946 - val_loss: 0.4159\n",
      "Epoch 747/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2938 - val_loss: 0.4160\n",
      "Epoch 748/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2638 - val_loss: 0.4161\n",
      "Epoch 749/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2421 - val_loss: 0.4161\n",
      "Epoch 750/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2776 - val_loss: 0.4161\n",
      "Epoch 751/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2496 - val_loss: 0.4166\n",
      "Epoch 752/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2666 - val_loss: 0.4165\n",
      "Epoch 753/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2785 - val_loss: 0.4164\n",
      "Epoch 754/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2959 - val_loss: 0.4167\n",
      "Epoch 755/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3018 - val_loss: 0.4170\n",
      "Epoch 756/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2943 - val_loss: 0.4167\n",
      "Epoch 757/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3104 - val_loss: 0.4165\n",
      "Epoch 758/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2778 - val_loss: 0.4162\n",
      "Epoch 759/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2788 - val_loss: 0.4157\n",
      "Epoch 760/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2642 - val_loss: 0.4152\n",
      "Epoch 761/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2525 - val_loss: 0.4149\n",
      "Epoch 762/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2897 - val_loss: 0.4143\n",
      "Epoch 763/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3010 - val_loss: 0.4139\n",
      "Epoch 764/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2782 - val_loss: 0.4139\n",
      "Epoch 765/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2499 - val_loss: 0.4139\n",
      "Epoch 766/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2724 - val_loss: 0.4134\n",
      "Epoch 767/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2861 - val_loss: 0.4128\n",
      "Epoch 768/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2769 - val_loss: 0.4132\n",
      "Epoch 769/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3088 - val_loss: 0.4131\n",
      "Epoch 770/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2613 - val_loss: 0.4132\n",
      "Epoch 771/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2892 - val_loss: 0.4133\n",
      "Epoch 772/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2583 - val_loss: 0.4135\n",
      "Epoch 773/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2802 - val_loss: 0.4136\n",
      "Epoch 774/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2799 - val_loss: 0.4142\n",
      "Epoch 775/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2790 - val_loss: 0.4144\n",
      "Epoch 776/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3090 - val_loss: 0.4143\n",
      "Epoch 777/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3064 - val_loss: 0.4141\n",
      "Epoch 778/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2756 - val_loss: 0.4134\n",
      "Epoch 779/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2586 - val_loss: 0.4130\n",
      "Epoch 780/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2584 - val_loss: 0.4129\n",
      "Epoch 781/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2917 - val_loss: 0.4127\n",
      "Epoch 782/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2608 - val_loss: 0.4131\n",
      "Epoch 783/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2845 - val_loss: 0.4134\n",
      "Epoch 784/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2701 - val_loss: 0.4137\n",
      "Epoch 785/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3042 - val_loss: 0.4137\n",
      "Epoch 786/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3051 - val_loss: 0.4132\n",
      "Epoch 787/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2765 - val_loss: 0.4128\n",
      "Epoch 788/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2701 - val_loss: 0.4123\n",
      "Epoch 789/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2746 - val_loss: 0.4123\n",
      "Epoch 790/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2589 - val_loss: 0.4121\n",
      "Epoch 791/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2501 - val_loss: 0.4122\n",
      "Epoch 792/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3053 - val_loss: 0.4121\n",
      "Epoch 793/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2611 - val_loss: 0.4116\n",
      "Epoch 794/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2864 - val_loss: 0.4116\n",
      "Epoch 795/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2400 - val_loss: 0.4122\n",
      "Epoch 796/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2628 - val_loss: 0.4124\n",
      "Epoch 797/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2522 - val_loss: 0.4126\n",
      "Epoch 798/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2717 - val_loss: 0.4123\n",
      "Epoch 799/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3079 - val_loss: 0.4120\n",
      "Epoch 800/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2411 - val_loss: 0.4121\n",
      "Epoch 801/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3260 - val_loss: 0.4119\n",
      "Epoch 802/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3017 - val_loss: 0.4116\n",
      "Epoch 803/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2814 - val_loss: 0.4115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 804/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2737 - val_loss: 0.4117\n",
      "Epoch 805/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2858 - val_loss: 0.4118\n",
      "Epoch 806/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2797 - val_loss: 0.4121\n",
      "Epoch 807/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2591 - val_loss: 0.4124\n",
      "Epoch 808/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2610 - val_loss: 0.4122\n",
      "Epoch 809/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2625 - val_loss: 0.4125\n",
      "Epoch 810/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2697 - val_loss: 0.4127\n",
      "Epoch 811/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2859 - val_loss: 0.4127\n",
      "Epoch 812/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2756 - val_loss: 0.4126\n",
      "Epoch 813/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3098 - val_loss: 0.4126\n",
      "Epoch 814/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2659 - val_loss: 0.4125\n",
      "Epoch 815/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2619 - val_loss: 0.4123\n",
      "Epoch 816/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2872 - val_loss: 0.4124\n",
      "Epoch 817/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3167 - val_loss: 0.4122\n",
      "Epoch 818/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2684 - val_loss: 0.4122\n",
      "Epoch 819/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2755 - val_loss: 0.4122\n",
      "Epoch 820/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2790 - val_loss: 0.4124\n",
      "Epoch 821/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2387 - val_loss: 0.4126\n",
      "Epoch 822/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2729 - val_loss: 0.4125\n",
      "Epoch 823/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2757 - val_loss: 0.4128\n",
      "Epoch 824/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2692 - val_loss: 0.4127\n",
      "Epoch 825/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2699 - val_loss: 0.4129\n",
      "Epoch 826/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2541 - val_loss: 0.4127\n",
      "Epoch 827/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2842 - val_loss: 0.4127\n",
      "Epoch 828/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2891 - val_loss: 0.4127\n",
      "Epoch 829/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2792 - val_loss: 0.4126\n",
      "Epoch 830/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2543 - val_loss: 0.4128\n",
      "Epoch 831/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2899 - val_loss: 0.4127\n",
      "Epoch 832/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2680 - val_loss: 0.4128\n",
      "Epoch 833/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2896 - val_loss: 0.4130\n",
      "Epoch 834/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3415 - val_loss: 0.4130\n",
      "Epoch 835/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2762 - val_loss: 0.4129\n",
      "Epoch 836/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2895 - val_loss: 0.4129\n",
      "Epoch 837/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2771 - val_loss: 0.4128\n",
      "Epoch 838/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2850 - val_loss: 0.4129\n",
      "Epoch 839/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3106 - val_loss: 0.4129\n",
      "Epoch 840/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2804 - val_loss: 0.4128\n",
      "Epoch 841/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2695 - val_loss: 0.4129\n",
      "Epoch 842/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3291 - val_loss: 0.4129\n",
      "Epoch 843/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2709 - val_loss: 0.4130\n",
      "Epoch 844/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2929 - val_loss: 0.4125\n",
      "Epoch 845/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2978 - val_loss: 0.4119\n",
      "Epoch 846/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2597 - val_loss: 0.4118\n",
      "Epoch 847/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3157 - val_loss: 0.4118\n",
      "Epoch 848/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2323 - val_loss: 0.4117\n",
      "Epoch 849/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2535 - val_loss: 0.4118\n",
      "Epoch 850/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2390 - val_loss: 0.4116\n",
      "Epoch 851/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2551 - val_loss: 0.4115\n",
      "Epoch 852/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2694 - val_loss: 0.4114\n",
      "Epoch 853/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2590 - val_loss: 0.4113\n",
      "Epoch 854/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2965 - val_loss: 0.4113\n",
      "Epoch 855/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2867 - val_loss: 0.4112\n",
      "Epoch 856/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2833 - val_loss: 0.4115\n",
      "Epoch 857/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2730 - val_loss: 0.4118\n",
      "Epoch 858/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2969 - val_loss: 0.4117\n",
      "Epoch 859/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2842 - val_loss: 0.4116\n",
      "Epoch 860/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2826 - val_loss: 0.4120\n",
      "Epoch 861/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2665 - val_loss: 0.4119\n",
      "Epoch 862/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2813 - val_loss: 0.4119\n",
      "Epoch 863/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3224 - val_loss: 0.4122\n",
      "Epoch 864/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2904 - val_loss: 0.4124\n",
      "Epoch 865/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2865 - val_loss: 0.4123\n",
      "Epoch 866/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2858 - val_loss: 0.4124\n",
      "Epoch 867/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3212 - val_loss: 0.4126\n",
      "Epoch 868/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2748 - val_loss: 0.4126\n",
      "Epoch 869/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2907 - val_loss: 0.4127\n",
      "Epoch 870/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2789 - val_loss: 0.4126\n",
      "Epoch 871/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2948 - val_loss: 0.4126\n",
      "Epoch 872/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2764 - val_loss: 0.4128\n",
      "Epoch 873/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2875 - val_loss: 0.4126\n",
      "Epoch 874/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2902 - val_loss: 0.4128\n",
      "Epoch 875/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3005 - val_loss: 0.4130\n",
      "Epoch 876/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2714 - val_loss: 0.4127\n",
      "Epoch 877/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2742 - val_loss: 0.4131\n",
      "Epoch 878/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2804 - val_loss: 0.4130\n",
      "Epoch 879/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2481 - val_loss: 0.4130\n",
      "Epoch 880/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2941 - val_loss: 0.4127\n",
      "Epoch 881/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2929 - val_loss: 0.4125\n",
      "Epoch 882/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2713 - val_loss: 0.4124\n",
      "Epoch 883/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2773 - val_loss: 0.4125\n",
      "Epoch 884/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2664 - val_loss: 0.4126\n",
      "Epoch 885/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2853 - val_loss: 0.4128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2811 - val_loss: 0.4128\n",
      "Epoch 887/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3058 - val_loss: 0.4126\n",
      "Epoch 888/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3220 - val_loss: 0.4128\n",
      "Epoch 889/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2654 - val_loss: 0.4130\n",
      "Epoch 890/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2532 - val_loss: 0.4131\n",
      "Epoch 891/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2991 - val_loss: 0.4130\n",
      "Epoch 892/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2832 - val_loss: 0.4130\n",
      "Epoch 893/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2477 - val_loss: 0.4134\n",
      "Epoch 894/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2901 - val_loss: 0.4131\n",
      "Epoch 895/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2686 - val_loss: 0.4131\n",
      "Epoch 896/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2925 - val_loss: 0.4129\n",
      "Epoch 897/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2653 - val_loss: 0.4131\n",
      "Epoch 898/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2793 - val_loss: 0.4131\n",
      "Epoch 899/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2468 - val_loss: 0.4131\n",
      "Epoch 900/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2722 - val_loss: 0.4130\n",
      "Epoch 901/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3018 - val_loss: 0.4135\n",
      "Epoch 902/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2760 - val_loss: 0.4133\n",
      "Epoch 903/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2611 - val_loss: 0.4132\n",
      "Epoch 904/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2794 - val_loss: 0.4132\n",
      "Epoch 905/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2575 - val_loss: 0.4133\n",
      "Epoch 906/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3258 - val_loss: 0.4133\n",
      "Epoch 907/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2426 - val_loss: 0.4135\n",
      "Epoch 908/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2944 - val_loss: 0.4135\n",
      "Epoch 909/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2926 - val_loss: 0.4136\n",
      "Epoch 910/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2775 - val_loss: 0.4138\n",
      "Epoch 911/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2707 - val_loss: 0.4138\n",
      "Epoch 912/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2556 - val_loss: 0.4136\n",
      "Epoch 913/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2537 - val_loss: 0.4135\n",
      "Epoch 914/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2731 - val_loss: 0.4128\n",
      "Epoch 915/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2767 - val_loss: 0.4131\n",
      "Epoch 916/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2959 - val_loss: 0.4129\n",
      "Epoch 917/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2939 - val_loss: 0.4126\n",
      "Epoch 918/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2474 - val_loss: 0.4126\n",
      "Epoch 919/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2548 - val_loss: 0.4124\n",
      "Epoch 920/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2604 - val_loss: 0.4126\n",
      "Epoch 921/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2706 - val_loss: 0.4128\n",
      "Epoch 922/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2953 - val_loss: 0.4130\n",
      "Epoch 923/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2929 - val_loss: 0.4127\n",
      "Epoch 924/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2695 - val_loss: 0.4124\n",
      "Epoch 925/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2817 - val_loss: 0.4125\n",
      "Epoch 926/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2720 - val_loss: 0.4127\n",
      "Epoch 927/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2439 - val_loss: 0.4125\n",
      "Epoch 928/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2861 - val_loss: 0.4127\n",
      "Epoch 929/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2811 - val_loss: 0.4127\n",
      "Epoch 930/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2373 - val_loss: 0.4129\n",
      "Epoch 931/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2768 - val_loss: 0.4127\n",
      "Epoch 932/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2888 - val_loss: 0.4126\n",
      "Epoch 933/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3176 - val_loss: 0.4127\n",
      "Epoch 934/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2765 - val_loss: 0.4128\n",
      "Epoch 935/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3187 - val_loss: 0.4126\n",
      "Epoch 936/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2708 - val_loss: 0.4126\n",
      "Epoch 937/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2877 - val_loss: 0.4129\n",
      "Epoch 938/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2918 - val_loss: 0.4131\n",
      "Epoch 939/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2786 - val_loss: 0.4132\n",
      "Epoch 940/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2983 - val_loss: 0.4133\n",
      "Epoch 941/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3051 - val_loss: 0.4134\n",
      "Epoch 942/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2723 - val_loss: 0.4130\n",
      "Epoch 943/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2656 - val_loss: 0.4128\n",
      "Epoch 944/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2755 - val_loss: 0.4129\n",
      "Epoch 945/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2975 - val_loss: 0.4129\n",
      "Epoch 946/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2742 - val_loss: 0.4129\n",
      "Epoch 947/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2730 - val_loss: 0.4128\n",
      "Epoch 948/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2937 - val_loss: 0.4124\n",
      "Epoch 949/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2711 - val_loss: 0.4124\n",
      "Epoch 950/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2832 - val_loss: 0.4126\n",
      "Epoch 951/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3380 - val_loss: 0.4124\n",
      "Epoch 952/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2473 - val_loss: 0.4127\n",
      "Epoch 953/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2667 - val_loss: 0.4130\n",
      "Epoch 954/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3174 - val_loss: 0.4130\n",
      "Epoch 955/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2939 - val_loss: 0.4126\n",
      "Epoch 956/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3094 - val_loss: 0.4127\n",
      "Epoch 957/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2915 - val_loss: 0.4124\n",
      "Epoch 958/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2788 - val_loss: 0.4126\n",
      "Epoch 959/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3056 - val_loss: 0.4127\n",
      "Epoch 960/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2511 - val_loss: 0.4129\n",
      "Epoch 961/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3069 - val_loss: 0.4128\n",
      "Epoch 962/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2704 - val_loss: 0.4126\n",
      "Epoch 963/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2755 - val_loss: 0.4123\n",
      "Epoch 964/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3220 - val_loss: 0.4122\n",
      "Epoch 965/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2772 - val_loss: 0.4121\n",
      "Epoch 966/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2808 - val_loss: 0.4123\n",
      "Epoch 967/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2758 - val_loss: 0.4122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2716 - val_loss: 0.4121\n",
      "Epoch 969/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2728 - val_loss: 0.4121\n",
      "Epoch 970/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2749 - val_loss: 0.4121\n",
      "Epoch 971/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2828 - val_loss: 0.4121\n",
      "Epoch 972/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2544 - val_loss: 0.4125\n",
      "Epoch 973/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2745 - val_loss: 0.4123\n",
      "Epoch 974/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2823 - val_loss: 0.4123\n",
      "Epoch 975/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3316 - val_loss: 0.4122\n",
      "Epoch 976/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2574 - val_loss: 0.4120\n",
      "Epoch 977/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2488 - val_loss: 0.4122\n",
      "Epoch 978/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2654 - val_loss: 0.4122\n",
      "Epoch 979/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2611 - val_loss: 0.4121\n",
      "Epoch 980/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2632 - val_loss: 0.4120\n",
      "Epoch 981/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2787 - val_loss: 0.4119\n",
      "Epoch 982/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2616 - val_loss: 0.4120\n",
      "Epoch 983/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2826 - val_loss: 0.4121\n",
      "Epoch 984/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2676 - val_loss: 0.4121\n",
      "Epoch 985/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3116 - val_loss: 0.4122\n",
      "Epoch 986/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2873 - val_loss: 0.4123\n",
      "Epoch 987/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2633 - val_loss: 0.4122\n",
      "Epoch 988/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2686 - val_loss: 0.4123\n",
      "Epoch 989/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2527 - val_loss: 0.4123\n",
      "Epoch 990/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2566 - val_loss: 0.4123\n",
      "Epoch 991/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2816 - val_loss: 0.4121\n",
      "Epoch 992/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2852 - val_loss: 0.4119\n",
      "Epoch 993/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2727 - val_loss: 0.4118\n",
      "Epoch 994/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2759 - val_loss: 0.4119\n",
      "Epoch 995/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2774 - val_loss: 0.4121\n",
      "Epoch 996/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2838 - val_loss: 0.4119\n",
      "Epoch 997/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2491 - val_loss: 0.4118\n",
      "Epoch 998/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2719 - val_loss: 0.4120\n",
      "Epoch 999/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2929 - val_loss: 0.4117\n",
      "Epoch 1000/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3048 - val_loss: 0.4119\n",
      "Epoch 1001/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2592 - val_loss: 0.4122\n",
      "Epoch 1002/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3011 - val_loss: 0.4123\n",
      "Epoch 1003/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2666 - val_loss: 0.4124\n",
      "Epoch 1004/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3048 - val_loss: 0.4125\n",
      "Epoch 1005/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2895 - val_loss: 0.4128\n",
      "Epoch 1006/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2334 - val_loss: 0.4130\n",
      "Epoch 1007/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2594 - val_loss: 0.4128\n",
      "Epoch 1008/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2535 - val_loss: 0.4129\n",
      "Epoch 1009/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2891 - val_loss: 0.4131\n",
      "Epoch 1010/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2950 - val_loss: 0.4131\n",
      "Epoch 1011/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2836 - val_loss: 0.4134\n",
      "Epoch 1012/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3094 - val_loss: 0.4136\n",
      "Epoch 1013/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2542 - val_loss: 0.4136\n",
      "Epoch 1014/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2620 - val_loss: 0.4137\n",
      "Epoch 1015/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3248 - val_loss: 0.4137\n",
      "Epoch 1016/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2758 - val_loss: 0.4136\n",
      "Epoch 1017/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2926 - val_loss: 0.4132\n",
      "Epoch 1018/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2834 - val_loss: 0.4128\n",
      "Epoch 1019/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2940 - val_loss: 0.4129\n",
      "Epoch 1020/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2692 - val_loss: 0.4128\n",
      "Epoch 1021/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2683 - val_loss: 0.4129\n",
      "Epoch 1022/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2916 - val_loss: 0.4129\n",
      "Epoch 1023/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2590 - val_loss: 0.4128\n",
      "Epoch 1024/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2917 - val_loss: 0.4127\n",
      "Epoch 1025/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3159 - val_loss: 0.4126\n",
      "Epoch 1026/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2509 - val_loss: 0.4127\n",
      "Epoch 1027/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2894 - val_loss: 0.4127\n",
      "Epoch 1028/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2538 - val_loss: 0.4127\n",
      "Epoch 1029/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2597 - val_loss: 0.4129\n",
      "Epoch 1030/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2625 - val_loss: 0.4130\n",
      "Epoch 1031/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2645 - val_loss: 0.4130\n",
      "Epoch 1032/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2624 - val_loss: 0.4127\n",
      "Epoch 1033/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2637 - val_loss: 0.4125\n",
      "Epoch 1034/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3014 - val_loss: 0.4123\n",
      "Epoch 1035/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2648 - val_loss: 0.4124\n",
      "Epoch 1036/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2506 - val_loss: 0.4122\n",
      "Epoch 1037/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2753 - val_loss: 0.4124\n",
      "Epoch 1038/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2761 - val_loss: 0.4122\n",
      "Epoch 1039/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2537 - val_loss: 0.4121\n",
      "Epoch 1040/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2805 - val_loss: 0.4121\n",
      "Epoch 1041/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3073 - val_loss: 0.4122\n",
      "Epoch 1042/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3131 - val_loss: 0.4121\n",
      "Epoch 1043/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3102 - val_loss: 0.4122\n",
      "Epoch 1044/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2514 - val_loss: 0.4124\n",
      "Epoch 1045/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3121 - val_loss: 0.4122\n",
      "Epoch 1046/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2806 - val_loss: 0.4120\n",
      "Epoch 1047/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2961 - val_loss: 0.4118\n",
      "Epoch 1048/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3345 - val_loss: 0.4120\n",
      "Epoch 1049/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2734 - val_loss: 0.4117\n",
      "Epoch 1050/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2649 - val_loss: 0.4119\n",
      "Epoch 1051/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2894 - val_loss: 0.4118\n",
      "Epoch 1052/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2992 - val_loss: 0.4116\n",
      "Epoch 1053/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3119 - val_loss: 0.4116\n",
      "Epoch 1054/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2412 - val_loss: 0.4117\n",
      "Epoch 1055/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3135 - val_loss: 0.4115\n",
      "Epoch 1056/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2611 - val_loss: 0.4116\n",
      "Epoch 1057/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3306 - val_loss: 0.4115\n",
      "Epoch 1058/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2410 - val_loss: 0.4117\n",
      "Epoch 1059/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2834 - val_loss: 0.4118\n",
      "Epoch 1060/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2942 - val_loss: 0.4119\n",
      "Epoch 1061/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2770 - val_loss: 0.4120\n",
      "Epoch 1062/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2674 - val_loss: 0.4119\n",
      "Epoch 1063/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2735 - val_loss: 0.4119\n",
      "Epoch 1064/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2756 - val_loss: 0.4117\n",
      "Epoch 1065/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2599 - val_loss: 0.4117\n",
      "Epoch 1066/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2876 - val_loss: 0.4119\n",
      "Epoch 1067/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2590 - val_loss: 0.4121\n",
      "Epoch 1068/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2860 - val_loss: 0.4124\n",
      "Epoch 1069/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2614 - val_loss: 0.4122\n",
      "Epoch 1070/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2714 - val_loss: 0.4121\n",
      "Epoch 1071/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2630 - val_loss: 0.4121\n",
      "Epoch 1072/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3071 - val_loss: 0.4122\n",
      "Epoch 1073/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2556 - val_loss: 0.4123\n",
      "Epoch 1074/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2672 - val_loss: 0.4124\n",
      "Epoch 1075/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2896 - val_loss: 0.4126\n",
      "Epoch 1076/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2828 - val_loss: 0.4126\n",
      "Epoch 1077/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2735 - val_loss: 0.4126\n",
      "Epoch 1078/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2735 - val_loss: 0.4129\n",
      "Epoch 1079/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2993 - val_loss: 0.4127\n",
      "Epoch 1080/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2880 - val_loss: 0.4127\n",
      "Epoch 1081/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2643 - val_loss: 0.4126\n",
      "Epoch 1082/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2518 - val_loss: 0.4126\n",
      "Epoch 1083/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2856 - val_loss: 0.4124\n",
      "Epoch 1084/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2664 - val_loss: 0.4124\n",
      "Epoch 1085/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2720 - val_loss: 0.4120\n",
      "Epoch 1086/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2802 - val_loss: 0.4121\n",
      "Epoch 1087/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2856 - val_loss: 0.4121\n",
      "Epoch 1088/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2816 - val_loss: 0.4124\n",
      "Epoch 1089/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2587 - val_loss: 0.4126\n",
      "Epoch 1090/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2583 - val_loss: 0.4123\n",
      "Epoch 1091/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2643 - val_loss: 0.4121\n",
      "Epoch 1092/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2509 - val_loss: 0.4121\n",
      "Epoch 1093/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2758 - val_loss: 0.4118\n",
      "Epoch 1094/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3144 - val_loss: 0.4117\n",
      "Epoch 1095/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2849 - val_loss: 0.4114\n",
      "Epoch 1096/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2978 - val_loss: 0.4115\n",
      "Epoch 1097/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2595 - val_loss: 0.4119\n",
      "Epoch 1098/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3140 - val_loss: 0.4118\n",
      "Epoch 1099/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2674 - val_loss: 0.4117\n",
      "Epoch 1100/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2918 - val_loss: 0.4118\n",
      "Epoch 1101/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2929 - val_loss: 0.4114\n",
      "Epoch 1102/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2719 - val_loss: 0.4111\n",
      "Epoch 1103/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2718 - val_loss: 0.4113\n",
      "Epoch 1104/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2845 - val_loss: 0.4116\n",
      "Epoch 1105/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2462 - val_loss: 0.4118\n",
      "Epoch 1106/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2617 - val_loss: 0.4118\n",
      "Epoch 1107/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2924 - val_loss: 0.4116\n",
      "Epoch 1108/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2903 - val_loss: 0.4117\n",
      "Epoch 1109/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2604 - val_loss: 0.4120\n",
      "Epoch 1110/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2689 - val_loss: 0.4117\n",
      "Epoch 1111/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2674 - val_loss: 0.4117\n",
      "Epoch 1112/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2911 - val_loss: 0.4119\n",
      "Epoch 1113/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2823 - val_loss: 0.4118\n",
      "Epoch 1114/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2587 - val_loss: 0.4119\n",
      "Epoch 1115/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2624 - val_loss: 0.4121\n",
      "Epoch 1116/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2513 - val_loss: 0.4120\n",
      "Epoch 1117/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2660 - val_loss: 0.4124\n",
      "Epoch 1118/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2862 - val_loss: 0.4123\n",
      "Epoch 1119/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2872 - val_loss: 0.4123\n",
      "Epoch 1120/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2560 - val_loss: 0.4122\n",
      "Epoch 1121/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2967 - val_loss: 0.4122\n",
      "Epoch 1122/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2889 - val_loss: 0.4121\n",
      "Epoch 1123/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2868 - val_loss: 0.4120\n",
      "Epoch 1124/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3013 - val_loss: 0.4118\n",
      "Epoch 1125/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2914 - val_loss: 0.4119\n",
      "Epoch 1126/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3186 - val_loss: 0.4117\n",
      "Epoch 1127/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3155 - val_loss: 0.4120\n",
      "Epoch 1128/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2695 - val_loss: 0.4120\n",
      "Epoch 1129/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2770 - val_loss: 0.4119\n",
      "Epoch 1130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2718 - val_loss: 0.4119\n",
      "Epoch 1131/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2997 - val_loss: 0.4119\n",
      "Epoch 1132/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2755 - val_loss: 0.4119\n",
      "Epoch 1133/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2976 - val_loss: 0.4121\n",
      "Epoch 1134/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2933 - val_loss: 0.4124\n",
      "Epoch 1135/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2748 - val_loss: 0.4125\n",
      "Epoch 1136/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2736 - val_loss: 0.4128\n",
      "Epoch 1137/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2755 - val_loss: 0.4126\n",
      "Epoch 1138/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3080 - val_loss: 0.4125\n",
      "Epoch 1139/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2528 - val_loss: 0.4124\n",
      "Epoch 1140/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2754 - val_loss: 0.4127\n",
      "Epoch 1141/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2599 - val_loss: 0.4124\n",
      "Epoch 1142/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2539 - val_loss: 0.4127\n",
      "Epoch 1143/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2461 - val_loss: 0.4123\n",
      "Epoch 1144/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2814 - val_loss: 0.4124\n",
      "Epoch 1145/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3168 - val_loss: 0.4125\n",
      "Epoch 1146/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2705 - val_loss: 0.4126\n",
      "Epoch 1147/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2890 - val_loss: 0.4126\n",
      "Epoch 1148/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3114 - val_loss: 0.4125\n",
      "Epoch 1149/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2667 - val_loss: 0.4124\n",
      "Epoch 1150/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2879 - val_loss: 0.4122\n",
      "Epoch 1151/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2917 - val_loss: 0.4123\n",
      "Epoch 1152/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2891 - val_loss: 0.4122\n",
      "Epoch 1153/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3093 - val_loss: 0.4122\n",
      "Epoch 1154/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2963 - val_loss: 0.4123\n",
      "Epoch 1155/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2492 - val_loss: 0.4124\n",
      "Epoch 1156/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3528 - val_loss: 0.4123\n",
      "Epoch 1157/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2740 - val_loss: 0.4123\n",
      "Epoch 1158/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2785 - val_loss: 0.4122\n",
      "Epoch 1159/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2558 - val_loss: 0.4122\n",
      "Epoch 1160/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2776 - val_loss: 0.4122\n",
      "Epoch 1161/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2607 - val_loss: 0.4123\n",
      "Epoch 1162/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2713 - val_loss: 0.4122\n",
      "Epoch 1163/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2645 - val_loss: 0.4123\n",
      "Epoch 1164/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2627 - val_loss: 0.4124\n",
      "Epoch 1165/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2667 - val_loss: 0.4127\n",
      "Epoch 1166/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2480 - val_loss: 0.4126\n",
      "Epoch 1167/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2832 - val_loss: 0.4126\n",
      "Epoch 1168/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2787 - val_loss: 0.4126\n",
      "Epoch 1169/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3117 - val_loss: 0.4128\n",
      "Epoch 1170/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3238 - val_loss: 0.4124\n",
      "Epoch 1171/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2620 - val_loss: 0.4121\n",
      "Epoch 1172/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2795 - val_loss: 0.4122\n",
      "Epoch 1173/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2741 - val_loss: 0.4122\n",
      "Epoch 1174/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2592 - val_loss: 0.4123\n",
      "Epoch 1175/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2834 - val_loss: 0.4120\n",
      "Epoch 1176/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2993 - val_loss: 0.4123\n",
      "Epoch 1177/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2784 - val_loss: 0.4125\n",
      "Epoch 1178/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2725 - val_loss: 0.4127\n",
      "Epoch 1179/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3099 - val_loss: 0.4126\n",
      "Epoch 1180/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2817 - val_loss: 0.4124\n",
      "Epoch 1181/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2749 - val_loss: 0.4124\n",
      "Epoch 1182/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2726 - val_loss: 0.4125\n",
      "Epoch 1183/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3676 - val_loss: 0.4125\n",
      "Epoch 1184/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2460 - val_loss: 0.4125\n",
      "Epoch 1185/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2798 - val_loss: 0.4125\n",
      "Epoch 1186/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2802 - val_loss: 0.4124\n",
      "Epoch 1187/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2603 - val_loss: 0.4121\n",
      "Epoch 1188/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2796 - val_loss: 0.4121\n",
      "Epoch 1189/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2843 - val_loss: 0.4119\n",
      "Epoch 1190/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2745 - val_loss: 0.4120\n",
      "Epoch 1191/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2743 - val_loss: 0.4120\n",
      "Epoch 1192/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2959 - val_loss: 0.4124\n",
      "Epoch 1193/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2545 - val_loss: 0.4124\n",
      "Epoch 1194/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2594 - val_loss: 0.4122\n",
      "Epoch 1195/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2739 - val_loss: 0.4123\n",
      "Epoch 1196/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2719 - val_loss: 0.4121\n",
      "Epoch 1197/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2890 - val_loss: 0.4121\n",
      "Epoch 1198/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2748 - val_loss: 0.4121\n",
      "Epoch 1199/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2778 - val_loss: 0.4120\n",
      "Epoch 1200/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2538 - val_loss: 0.4120\n",
      "Epoch 1201/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2828 - val_loss: 0.4120\n",
      "Epoch 1202/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2425 - val_loss: 0.4122\n",
      "Epoch 1203/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2631 - val_loss: 0.4122\n",
      "Epoch 1204/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2873 - val_loss: 0.4121\n",
      "Epoch 1205/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2591 - val_loss: 0.4120\n",
      "Epoch 1206/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2485 - val_loss: 0.4119\n",
      "Epoch 1207/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2671 - val_loss: 0.4118\n",
      "Epoch 1208/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2792 - val_loss: 0.4119\n",
      "Epoch 1209/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2703 - val_loss: 0.4120\n",
      "Epoch 1210/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2623 - val_loss: 0.4118\n",
      "Epoch 1211/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2679 - val_loss: 0.4119\n",
      "Epoch 1212/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2764 - val_loss: 0.4118\n",
      "Epoch 1213/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3484 - val_loss: 0.4118\n",
      "Epoch 1214/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2626 - val_loss: 0.4116\n",
      "Epoch 1215/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2872 - val_loss: 0.4114\n",
      "Epoch 1216/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2812 - val_loss: 0.4111\n",
      "Epoch 1217/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2765 - val_loss: 0.4113\n",
      "Epoch 1218/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2699 - val_loss: 0.4116\n",
      "Epoch 1219/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2909 - val_loss: 0.4118\n",
      "Epoch 1220/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2782 - val_loss: 0.4119\n",
      "Epoch 1221/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2495 - val_loss: 0.4121\n",
      "Epoch 1222/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2715 - val_loss: 0.4123\n",
      "Epoch 1223/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2941 - val_loss: 0.4124\n",
      "Epoch 1224/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.4125\n",
      "Epoch 1225/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2834 - val_loss: 0.4124\n",
      "Epoch 1226/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2661 - val_loss: 0.4125\n",
      "Epoch 1227/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2919 - val_loss: 0.4125\n",
      "Epoch 1228/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2799 - val_loss: 0.4125\n",
      "Epoch 1229/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2762 - val_loss: 0.4123\n",
      "Epoch 1230/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2741 - val_loss: 0.4122\n",
      "Epoch 1231/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2608 - val_loss: 0.4121\n",
      "Epoch 1232/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2842 - val_loss: 0.4119\n",
      "Epoch 1233/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2780 - val_loss: 0.4118\n",
      "Epoch 1234/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2705 - val_loss: 0.4117\n",
      "Epoch 1235/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2659 - val_loss: 0.4119\n",
      "Epoch 1236/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2522 - val_loss: 0.4120\n",
      "Epoch 1237/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3161 - val_loss: 0.4119\n",
      "Epoch 1238/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2498 - val_loss: 0.4118\n",
      "Epoch 1239/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2561 - val_loss: 0.4117\n",
      "Epoch 1240/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2874 - val_loss: 0.4118\n",
      "Epoch 1241/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2679 - val_loss: 0.4118\n",
      "Epoch 1242/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2581 - val_loss: 0.4121\n",
      "Epoch 1243/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2796 - val_loss: 0.4120\n",
      "Epoch 1244/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.4120\n",
      "Epoch 1245/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2631 - val_loss: 0.4120\n",
      "Epoch 1246/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2621 - val_loss: 0.4120\n",
      "Epoch 1247/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2654 - val_loss: 0.4119\n",
      "Epoch 1248/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2691 - val_loss: 0.4119\n",
      "Epoch 1249/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3021 - val_loss: 0.4120\n",
      "Epoch 1250/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2924 - val_loss: 0.4119\n",
      "Epoch 1251/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2614 - val_loss: 0.4121\n",
      "Epoch 1252/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2435 - val_loss: 0.4124\n",
      "Epoch 1253/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2735 - val_loss: 0.4122\n",
      "Epoch 1254/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2837 - val_loss: 0.4121\n",
      "Epoch 1255/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2643 - val_loss: 0.4121\n",
      "Epoch 1256/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2836 - val_loss: 0.4122\n",
      "Epoch 1257/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2567 - val_loss: 0.4124\n",
      "Epoch 1258/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2695 - val_loss: 0.4124\n",
      "Epoch 1259/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2852 - val_loss: 0.4124\n",
      "Epoch 1260/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2395 - val_loss: 0.4126\n",
      "Epoch 1261/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2602 - val_loss: 0.4126\n",
      "Epoch 1262/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2499 - val_loss: 0.4128\n",
      "Epoch 1263/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2755 - val_loss: 0.4128\n",
      "Epoch 1264/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2498 - val_loss: 0.4127\n",
      "Epoch 1265/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2693 - val_loss: 0.4127\n",
      "Epoch 1266/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3056 - val_loss: 0.4124\n",
      "Epoch 1267/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2856 - val_loss: 0.4121\n",
      "Epoch 1268/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.4120\n",
      "Epoch 1269/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2652 - val_loss: 0.4119\n",
      "Epoch 1270/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2842 - val_loss: 0.4118\n",
      "Epoch 1271/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2728 - val_loss: 0.4117\n",
      "Epoch 1272/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2847 - val_loss: 0.4115\n",
      "Epoch 1273/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2585 - val_loss: 0.4113\n",
      "Epoch 1274/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2878 - val_loss: 0.4118\n",
      "Epoch 1275/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2707 - val_loss: 0.4115\n",
      "Epoch 1276/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3189 - val_loss: 0.4115\n",
      "Epoch 1277/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2719 - val_loss: 0.4115\n",
      "Epoch 1278/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2661 - val_loss: 0.4112\n",
      "Epoch 1279/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2789 - val_loss: 0.4114\n",
      "Epoch 1280/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2470 - val_loss: 0.4114\n",
      "Epoch 1281/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2621 - val_loss: 0.4116\n",
      "Epoch 1282/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2998 - val_loss: 0.4117\n",
      "Epoch 1283/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2774 - val_loss: 0.4117\n",
      "Epoch 1284/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2801 - val_loss: 0.4120\n",
      "Epoch 1285/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2605 - val_loss: 0.4119\n",
      "Epoch 1286/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2706 - val_loss: 0.4119\n",
      "Epoch 1287/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2537 - val_loss: 0.4121\n",
      "Epoch 1288/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2838 - val_loss: 0.4124\n",
      "Epoch 1289/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2779 - val_loss: 0.4125\n",
      "Epoch 1290/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3003 - val_loss: 0.4124\n",
      "Epoch 1291/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2683 - val_loss: 0.4122\n",
      "Epoch 1292/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2672 - val_loss: 0.4124\n",
      "Epoch 1293/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2797 - val_loss: 0.4123\n",
      "Epoch 1294/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2789 - val_loss: 0.4123\n",
      "Epoch 1295/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3100 - val_loss: 0.4125\n",
      "Epoch 1296/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2530 - val_loss: 0.4125\n",
      "Epoch 1297/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2908 - val_loss: 0.4129\n",
      "Epoch 1298/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3161 - val_loss: 0.4134\n",
      "Epoch 1299/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2867 - val_loss: 0.4136\n",
      "Epoch 1300/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2701 - val_loss: 0.4135\n",
      "Epoch 1301/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3053 - val_loss: 0.4132\n",
      "Epoch 1302/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2669 - val_loss: 0.4132\n",
      "Epoch 1303/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2578 - val_loss: 0.4131\n",
      "Epoch 1304/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2600 - val_loss: 0.4131\n",
      "Epoch 1305/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3250 - val_loss: 0.4129\n",
      "Epoch 1306/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2955 - val_loss: 0.4130\n",
      "Epoch 1307/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2310 - val_loss: 0.4128\n",
      "Epoch 1308/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2751 - val_loss: 0.4130\n",
      "Epoch 1309/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2884 - val_loss: 0.4132\n",
      "Epoch 1310/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2677 - val_loss: 0.4132\n",
      "Epoch 1311/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2887 - val_loss: 0.4132\n",
      "Epoch 1312/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2660 - val_loss: 0.4130\n",
      "Epoch 1313/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2635 - val_loss: 0.4131\n",
      "Epoch 1314/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2430 - val_loss: 0.4132\n",
      "Epoch 1315/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2649 - val_loss: 0.4133\n",
      "Epoch 1316/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3059 - val_loss: 0.4131\n",
      "Epoch 1317/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2888 - val_loss: 0.4130\n",
      "Epoch 1318/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2682 - val_loss: 0.4128\n",
      "Epoch 1319/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2791 - val_loss: 0.4129\n",
      "Epoch 1320/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2588 - val_loss: 0.4130\n",
      "Epoch 1321/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2531 - val_loss: 0.4128\n",
      "Epoch 1322/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2493 - val_loss: 0.4129\n",
      "Epoch 1323/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3073 - val_loss: 0.4129\n",
      "Epoch 1324/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2932 - val_loss: 0.4132\n",
      "Epoch 1325/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2664 - val_loss: 0.4135\n",
      "Epoch 1326/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3167 - val_loss: 0.4134\n",
      "Epoch 1327/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2899 - val_loss: 0.4135\n",
      "Epoch 1328/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3035 - val_loss: 0.4133\n",
      "Epoch 1329/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2753 - val_loss: 0.4134\n",
      "Epoch 1330/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2507 - val_loss: 0.4130\n",
      "Epoch 1331/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2654 - val_loss: 0.4131\n",
      "Epoch 1332/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2761 - val_loss: 0.4132\n",
      "Epoch 1333/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2617 - val_loss: 0.4133\n",
      "Epoch 1334/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2421 - val_loss: 0.4133\n",
      "Epoch 1335/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2574 - val_loss: 0.4133\n",
      "Epoch 1336/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2910 - val_loss: 0.4133\n",
      "Epoch 1337/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2593 - val_loss: 0.4131\n",
      "Epoch 1338/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2611 - val_loss: 0.4129\n",
      "Epoch 1339/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2807 - val_loss: 0.4127\n",
      "Epoch 1340/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3041 - val_loss: 0.4123\n",
      "Epoch 1341/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3120 - val_loss: 0.4123\n",
      "Epoch 1342/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2743 - val_loss: 0.4123\n",
      "Epoch 1343/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2821 - val_loss: 0.4121\n",
      "Epoch 1344/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2795 - val_loss: 0.4121\n",
      "Epoch 1345/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2542 - val_loss: 0.4121\n",
      "Epoch 1346/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2569 - val_loss: 0.4122\n",
      "Epoch 1347/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2763 - val_loss: 0.4120\n",
      "Epoch 1348/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3048 - val_loss: 0.4119\n",
      "Epoch 1349/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2845 - val_loss: 0.4120\n",
      "Epoch 1350/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2839 - val_loss: 0.4120\n",
      "Epoch 1351/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2932 - val_loss: 0.4120\n",
      "Epoch 1352/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2743 - val_loss: 0.4122\n",
      "Epoch 1353/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3407 - val_loss: 0.4123\n",
      "Epoch 1354/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2733 - val_loss: 0.4123\n",
      "Epoch 1355/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2830 - val_loss: 0.4123\n",
      "Epoch 1356/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2522 - val_loss: 0.4122\n",
      "Epoch 1357/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2397 - val_loss: 0.4122\n",
      "Epoch 1358/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2510 - val_loss: 0.4123\n",
      "Epoch 1359/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2787 - val_loss: 0.4123\n",
      "Epoch 1360/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2644 - val_loss: 0.4121\n",
      "Epoch 1361/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2854 - val_loss: 0.4118\n",
      "Epoch 1362/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2828 - val_loss: 0.4118\n",
      "Epoch 1363/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2840 - val_loss: 0.4112\n",
      "Epoch 1364/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2719 - val_loss: 0.4113\n",
      "Epoch 1365/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2864 - val_loss: 0.4113\n",
      "Epoch 1366/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2829 - val_loss: 0.4115\n",
      "Epoch 1367/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2641 - val_loss: 0.4115\n",
      "Epoch 1368/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2591 - val_loss: 0.4115\n",
      "Epoch 1369/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2772 - val_loss: 0.4118\n",
      "Epoch 1370/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2641 - val_loss: 0.4116\n",
      "Epoch 1371/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2660 - val_loss: 0.4117\n",
      "Epoch 1372/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2737 - val_loss: 0.4118\n",
      "Epoch 1373/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2832 - val_loss: 0.4117\n",
      "Epoch 1374/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2672 - val_loss: 0.4118\n",
      "Epoch 1375/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2658 - val_loss: 0.4120\n",
      "Epoch 1376/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2950 - val_loss: 0.4120\n",
      "Epoch 1377/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2502 - val_loss: 0.4121\n",
      "Epoch 1378/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2628 - val_loss: 0.4120\n",
      "Epoch 1379/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2898 - val_loss: 0.4120\n",
      "Epoch 1380/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2984 - val_loss: 0.4123\n",
      "Epoch 1381/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2764 - val_loss: 0.4121\n",
      "Epoch 1382/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2811 - val_loss: 0.4123\n",
      "Epoch 1383/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2684 - val_loss: 0.4121\n",
      "Epoch 1384/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2478 - val_loss: 0.4120\n",
      "Epoch 1385/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2670 - val_loss: 0.4119\n",
      "Epoch 1386/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2647 - val_loss: 0.4119\n",
      "Epoch 1387/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2392 - val_loss: 0.4120\n",
      "Epoch 1388/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2568 - val_loss: 0.4121\n",
      "Epoch 1389/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2896 - val_loss: 0.4123\n",
      "Epoch 1390/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2662 - val_loss: 0.4126\n",
      "Epoch 1391/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2661 - val_loss: 0.4125\n",
      "Epoch 1392/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2594 - val_loss: 0.4125\n",
      "Epoch 1393/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3020 - val_loss: 0.4126\n",
      "Epoch 1394/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3158 - val_loss: 0.4125\n",
      "Epoch 1395/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2762 - val_loss: 0.4124\n",
      "Epoch 1396/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2924 - val_loss: 0.4123\n",
      "Epoch 1397/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2774 - val_loss: 0.4128\n",
      "Epoch 1398/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2596 - val_loss: 0.4127\n",
      "Epoch 1399/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2803 - val_loss: 0.4127\n",
      "Epoch 1400/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2745 - val_loss: 0.4128\n",
      "Epoch 1401/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2650 - val_loss: 0.4126\n",
      "Epoch 1402/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2835 - val_loss: 0.4126\n",
      "Epoch 1403/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2662 - val_loss: 0.4125\n",
      "Epoch 1404/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2934 - val_loss: 0.4124\n",
      "Epoch 1405/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2758 - val_loss: 0.4122\n",
      "Epoch 1406/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2684 - val_loss: 0.4122\n",
      "Epoch 1407/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2842 - val_loss: 0.4125\n",
      "Epoch 1408/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2993 - val_loss: 0.4125\n",
      "Epoch 1409/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2805 - val_loss: 0.4125\n",
      "Epoch 1410/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2561 - val_loss: 0.4122\n",
      "Epoch 1411/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2971 - val_loss: 0.4123\n",
      "Epoch 1412/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2766 - val_loss: 0.4122\n",
      "Epoch 1413/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2472 - val_loss: 0.4121\n",
      "Epoch 1414/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3134 - val_loss: 0.4125\n",
      "Epoch 1415/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2691 - val_loss: 0.4125\n",
      "Epoch 1416/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2826 - val_loss: 0.4125\n",
      "Epoch 1417/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2778 - val_loss: 0.4126\n",
      "Epoch 1418/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2876 - val_loss: 0.4124\n",
      "Epoch 1419/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2830 - val_loss: 0.4125\n",
      "Epoch 1420/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2626 - val_loss: 0.4124\n",
      "Epoch 1421/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2576 - val_loss: 0.4126\n",
      "Epoch 1422/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2654 - val_loss: 0.4126\n",
      "Epoch 1423/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2777 - val_loss: 0.4128\n",
      "Epoch 1424/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2732 - val_loss: 0.4128\n",
      "Epoch 1425/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2800 - val_loss: 0.4128\n",
      "Epoch 1426/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3094 - val_loss: 0.4125\n",
      "Epoch 1427/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2865 - val_loss: 0.4123\n",
      "Epoch 1428/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2701 - val_loss: 0.4121\n",
      "Epoch 1429/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2799 - val_loss: 0.4119\n",
      "Epoch 1430/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2924 - val_loss: 0.4117\n",
      "Epoch 1431/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2868 - val_loss: 0.4117\n",
      "Epoch 1432/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2508 - val_loss: 0.4118\n",
      "Epoch 1433/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2955 - val_loss: 0.4120\n",
      "Epoch 1434/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2730 - val_loss: 0.4119\n",
      "Epoch 1435/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2701 - val_loss: 0.4119\n",
      "Epoch 1436/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2591 - val_loss: 0.4118\n",
      "Epoch 1437/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2806 - val_loss: 0.4114\n",
      "Epoch 1438/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2462 - val_loss: 0.4116\n",
      "Epoch 1439/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2686 - val_loss: 0.4117\n",
      "Epoch 1440/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2442 - val_loss: 0.4118\n",
      "Epoch 1441/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2670 - val_loss: 0.4115\n",
      "Epoch 1442/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2926 - val_loss: 0.4115\n",
      "Epoch 1443/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2747 - val_loss: 0.4113\n",
      "Epoch 1444/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2899 - val_loss: 0.4115\n",
      "Epoch 1445/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2676 - val_loss: 0.4117\n",
      "Epoch 1446/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2846 - val_loss: 0.4117\n",
      "Epoch 1447/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2783 - val_loss: 0.4117\n",
      "Epoch 1448/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2663 - val_loss: 0.4117\n",
      "Epoch 1449/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2614 - val_loss: 0.4117\n",
      "Epoch 1450/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2472 - val_loss: 0.4117\n",
      "Epoch 1451/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2692 - val_loss: 0.4117\n",
      "Epoch 1452/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2873 - val_loss: 0.4117\n",
      "Epoch 1453/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2592 - val_loss: 0.4119\n",
      "Epoch 1454/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3166 - val_loss: 0.4118\n",
      "Epoch 1455/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2760 - val_loss: 0.4117\n",
      "Epoch 1456/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2891 - val_loss: 0.4118\n",
      "Epoch 1457/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2763 - val_loss: 0.4118\n",
      "Epoch 1458/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2592 - val_loss: 0.4117\n",
      "Epoch 1459/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2886 - val_loss: 0.4116\n",
      "Epoch 1460/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2882 - val_loss: 0.4117\n",
      "Epoch 1461/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2569 - val_loss: 0.4118\n",
      "Epoch 1462/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3102 - val_loss: 0.4117\n",
      "Epoch 1463/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2647 - val_loss: 0.4117\n",
      "Epoch 1464/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2865 - val_loss: 0.4114\n",
      "Epoch 1465/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3107 - val_loss: 0.4110\n",
      "Epoch 1466/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3253 - val_loss: 0.4109\n",
      "Epoch 1467/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2857 - val_loss: 0.4112\n",
      "Epoch 1468/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2832 - val_loss: 0.4111\n",
      "Epoch 1469/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2766 - val_loss: 0.4113\n",
      "Epoch 1470/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2728 - val_loss: 0.4113\n",
      "Epoch 1471/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2586 - val_loss: 0.4111\n",
      "Epoch 1472/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2673 - val_loss: 0.4110\n",
      "Epoch 1473/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2790 - val_loss: 0.4110\n",
      "Epoch 1474/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2912 - val_loss: 0.4111\n",
      "Epoch 1475/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2822 - val_loss: 0.4111\n",
      "Epoch 1476/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2597 - val_loss: 0.4111\n",
      "Epoch 1477/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2633 - val_loss: 0.4110\n",
      "Epoch 1478/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2747 - val_loss: 0.4103\n",
      "Epoch 1479/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3002 - val_loss: 0.4105\n",
      "Epoch 1480/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2573 - val_loss: 0.4106\n",
      "Epoch 1481/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2395 - val_loss: 0.4107\n",
      "Epoch 1482/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2510 - val_loss: 0.4108\n",
      "Epoch 1483/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2437 - val_loss: 0.4109\n",
      "Epoch 1484/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2550 - val_loss: 0.4109\n",
      "Epoch 1485/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2638 - val_loss: 0.4110\n",
      "Epoch 1486/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3167 - val_loss: 0.4107\n",
      "Epoch 1487/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2891 - val_loss: 0.4106\n",
      "Epoch 1488/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2740 - val_loss: 0.4109\n",
      "Epoch 1489/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2630 - val_loss: 0.4110\n",
      "Epoch 1490/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2819 - val_loss: 0.4110\n",
      "Epoch 1491/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2905 - val_loss: 0.4110\n",
      "Epoch 1492/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2780 - val_loss: 0.4111\n",
      "Epoch 1493/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2996 - val_loss: 0.4108\n",
      "Epoch 1494/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2542 - val_loss: 0.4107\n",
      "Epoch 1495/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3012 - val_loss: 0.4108\n",
      "Epoch 1496/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3043 - val_loss: 0.4107\n",
      "Epoch 1497/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2588 - val_loss: 0.4107\n",
      "Epoch 1498/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2760 - val_loss: 0.4107\n",
      "Epoch 1499/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2696 - val_loss: 0.4106\n",
      "Epoch 1500/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2557 - val_loss: 0.4107\n",
      "Epoch 1501/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2778 - val_loss: 0.4110\n",
      "Epoch 1502/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2633 - val_loss: 0.4110\n",
      "Epoch 1503/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2653 - val_loss: 0.4111\n",
      "Epoch 1504/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2678 - val_loss: 0.4111\n",
      "Epoch 1505/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2704 - val_loss: 0.4110\n",
      "Epoch 1506/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2483 - val_loss: 0.4111\n",
      "Epoch 1507/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2977 - val_loss: 0.4113\n",
      "Epoch 1508/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2491 - val_loss: 0.4115\n",
      "Epoch 1509/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2609 - val_loss: 0.4116\n",
      "Epoch 1510/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2640 - val_loss: 0.4117\n",
      "Epoch 1511/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2899 - val_loss: 0.4115\n",
      "Epoch 1512/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2528 - val_loss: 0.4116\n",
      "Epoch 1513/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3228 - val_loss: 0.4115\n",
      "Epoch 1514/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2841 - val_loss: 0.4114\n",
      "Epoch 1515/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3257 - val_loss: 0.4114\n",
      "Epoch 1516/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2597 - val_loss: 0.4115\n",
      "Epoch 1517/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2573 - val_loss: 0.4118\n",
      "Epoch 1518/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2779 - val_loss: 0.4117\n",
      "Epoch 1519/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3019 - val_loss: 0.4120\n",
      "Epoch 1520/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2610 - val_loss: 0.4121\n",
      "Epoch 1521/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3386 - val_loss: 0.4122\n",
      "Epoch 1522/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2783 - val_loss: 0.4125\n",
      "Epoch 1523/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2430 - val_loss: 0.4126\n",
      "Epoch 1524/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.4126\n",
      "Epoch 1525/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3130 - val_loss: 0.4127\n",
      "Epoch 1526/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2501 - val_loss: 0.4128\n",
      "Epoch 1527/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3125 - val_loss: 0.4127\n",
      "Epoch 1528/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2952 - val_loss: 0.4127\n",
      "Epoch 1529/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2653 - val_loss: 0.4128\n",
      "Epoch 1530/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2920 - val_loss: 0.4127\n",
      "Epoch 1531/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2716 - val_loss: 0.4126\n",
      "Epoch 1532/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2473 - val_loss: 0.4126\n",
      "Epoch 1533/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2854 - val_loss: 0.4123\n",
      "Epoch 1534/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2541 - val_loss: 0.4123\n",
      "Epoch 1535/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2657 - val_loss: 0.4124\n",
      "Epoch 1536/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3135 - val_loss: 0.4123\n",
      "Epoch 1537/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3137 - val_loss: 0.4121\n",
      "Epoch 1538/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2680 - val_loss: 0.4123\n",
      "Epoch 1539/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2677 - val_loss: 0.4121\n",
      "Epoch 1540/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2587 - val_loss: 0.4122\n",
      "Epoch 1541/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2785 - val_loss: 0.4122\n",
      "Epoch 1542/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2787 - val_loss: 0.4124\n",
      "Epoch 1543/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2822 - val_loss: 0.4127\n",
      "Epoch 1544/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2637 - val_loss: 0.4128\n",
      "Epoch 1545/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2363 - val_loss: 0.4128\n",
      "Epoch 1546/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3193 - val_loss: 0.4125\n",
      "Epoch 1547/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2673 - val_loss: 0.4123\n",
      "Epoch 1548/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3017 - val_loss: 0.4125\n",
      "Epoch 1549/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.4126\n",
      "Epoch 1550/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2772 - val_loss: 0.4124\n",
      "Epoch 1551/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2562 - val_loss: 0.4124\n",
      "Epoch 1552/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2648 - val_loss: 0.4124\n",
      "Epoch 1553/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2678 - val_loss: 0.4125\n",
      "Epoch 1554/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2398 - val_loss: 0.4126\n",
      "Epoch 1555/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3105 - val_loss: 0.4127\n",
      "Epoch 1556/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2354 - val_loss: 0.4126\n",
      "Epoch 1557/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2502 - val_loss: 0.4127\n",
      "Epoch 1558/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2605 - val_loss: 0.4127\n",
      "Epoch 1559/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3009 - val_loss: 0.4124\n",
      "Epoch 1560/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2845 - val_loss: 0.4125\n",
      "Epoch 1561/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2488 - val_loss: 0.4127\n",
      "Epoch 1562/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2841 - val_loss: 0.4129\n",
      "Epoch 1563/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2848 - val_loss: 0.4130\n",
      "Epoch 1564/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.4132\n",
      "Epoch 1565/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2711 - val_loss: 0.4132\n",
      "Epoch 1566/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.4131\n",
      "Epoch 1567/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2830 - val_loss: 0.4131\n",
      "Epoch 1568/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2504 - val_loss: 0.4133\n",
      "Epoch 1569/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2519 - val_loss: 0.4134\n",
      "Epoch 1570/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2769 - val_loss: 0.4132\n",
      "Epoch 1571/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2512 - val_loss: 0.4130\n",
      "Epoch 1572/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.4131\n",
      "Epoch 1573/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2752 - val_loss: 0.4129\n",
      "Epoch 1574/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2784 - val_loss: 0.4132\n",
      "Epoch 1575/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2851 - val_loss: 0.4130\n",
      "Epoch 1576/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2914 - val_loss: 0.4129\n",
      "Epoch 1577/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2651 - val_loss: 0.4128\n",
      "Epoch 1578/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2430 - val_loss: 0.4128\n",
      "Epoch 1579/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2840 - val_loss: 0.4128\n",
      "Epoch 1580/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2749 - val_loss: 0.4129\n",
      "Epoch 1581/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2499 - val_loss: 0.4129\n",
      "Epoch 1582/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2481 - val_loss: 0.4126\n",
      "Epoch 1583/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2930 - val_loss: 0.4123\n",
      "Epoch 1584/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2824 - val_loss: 0.4124\n",
      "Epoch 1585/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2827 - val_loss: 0.4122\n",
      "Epoch 1586/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2793 - val_loss: 0.4123\n",
      "Epoch 1587/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3035 - val_loss: 0.4120\n",
      "Epoch 1588/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2888 - val_loss: 0.4122\n",
      "Epoch 1589/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2973 - val_loss: 0.4121\n",
      "Epoch 1590/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2583 - val_loss: 0.4117\n",
      "Epoch 1591/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2759 - val_loss: 0.4117\n",
      "Epoch 1592/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2738 - val_loss: 0.4115\n",
      "Epoch 1593/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2855 - val_loss: 0.4115\n",
      "Epoch 1594/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2568 - val_loss: 0.4116\n",
      "Epoch 1595/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2737 - val_loss: 0.4115\n",
      "Epoch 1596/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2678 - val_loss: 0.4115\n",
      "Epoch 1597/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2500 - val_loss: 0.4115\n",
      "Epoch 1598/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2563 - val_loss: 0.4116\n",
      "Epoch 1599/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3126 - val_loss: 0.4116\n",
      "Epoch 1600/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2733 - val_loss: 0.4115\n",
      "Epoch 1601/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2721 - val_loss: 0.4114\n",
      "Epoch 1602/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3087 - val_loss: 0.4112\n",
      "Epoch 1603/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2865 - val_loss: 0.4111\n",
      "Epoch 1604/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2668 - val_loss: 0.4111\n",
      "Epoch 1605/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2450 - val_loss: 0.4113\n",
      "Epoch 1606/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3039 - val_loss: 0.4113\n",
      "Epoch 1607/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2588 - val_loss: 0.4113\n",
      "Epoch 1608/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3042 - val_loss: 0.4113\n",
      "Epoch 1609/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2639 - val_loss: 0.4114\n",
      "Epoch 1610/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2636 - val_loss: 0.4115\n",
      "Epoch 1611/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2716 - val_loss: 0.4113\n",
      "Epoch 1612/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2782 - val_loss: 0.4112\n",
      "Epoch 1613/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2768 - val_loss: 0.4111\n",
      "Epoch 1614/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2761 - val_loss: 0.4109\n",
      "Epoch 1615/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2732 - val_loss: 0.4110\n",
      "Epoch 1616/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3198 - val_loss: 0.4109\n",
      "Epoch 1617/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2882 - val_loss: 0.4112\n",
      "Epoch 1618/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3146 - val_loss: 0.4114\n",
      "Epoch 1619/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2727 - val_loss: 0.4116\n",
      "Epoch 1620/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2912 - val_loss: 0.4119\n",
      "Epoch 1621/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2943 - val_loss: 0.4117\n",
      "Epoch 1622/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2615 - val_loss: 0.4120\n",
      "Epoch 1623/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2653 - val_loss: 0.4119\n",
      "Epoch 1624/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2951 - val_loss: 0.4121\n",
      "Epoch 1625/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2785 - val_loss: 0.4123\n",
      "Epoch 1626/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2813 - val_loss: 0.4123\n",
      "Epoch 1627/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3141 - val_loss: 0.4122\n",
      "Epoch 1628/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2786 - val_loss: 0.4123\n",
      "Epoch 1629/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2846 - val_loss: 0.4122\n",
      "Epoch 1630/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3034 - val_loss: 0.4121\n",
      "Epoch 1631/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2937 - val_loss: 0.4118\n",
      "Epoch 1632/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2582 - val_loss: 0.4119\n",
      "Epoch 1633/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2798 - val_loss: 0.4120\n",
      "Epoch 1634/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2698 - val_loss: 0.4118\n",
      "Epoch 1635/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3006 - val_loss: 0.4116\n",
      "Epoch 1636/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2940 - val_loss: 0.4113\n",
      "Epoch 1637/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2612 - val_loss: 0.4114\n",
      "Epoch 1638/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2755 - val_loss: 0.4116\n",
      "Epoch 1639/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2896 - val_loss: 0.4117\n",
      "Epoch 1640/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2646 - val_loss: 0.4115\n",
      "Epoch 1641/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2522 - val_loss: 0.4113\n",
      "Epoch 1642/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3241 - val_loss: 0.4115\n",
      "Epoch 1643/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2631 - val_loss: 0.4112\n",
      "Epoch 1644/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2979 - val_loss: 0.4111\n",
      "Epoch 1645/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3066 - val_loss: 0.4112\n",
      "Epoch 1646/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2654 - val_loss: 0.4113\n",
      "Epoch 1647/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2980 - val_loss: 0.4114\n",
      "Epoch 1648/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2575 - val_loss: 0.4115\n",
      "Epoch 1649/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2497 - val_loss: 0.4115\n",
      "Epoch 1650/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2880 - val_loss: 0.4112\n",
      "Epoch 1651/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2902 - val_loss: 0.4114\n",
      "Epoch 1652/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2723 - val_loss: 0.4114\n",
      "Epoch 1653/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2803 - val_loss: 0.4116\n",
      "Epoch 1654/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2913 - val_loss: 0.4117\n",
      "Epoch 1655/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2656 - val_loss: 0.4117\n",
      "Epoch 1656/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2734 - val_loss: 0.4114\n",
      "Epoch 1657/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2685 - val_loss: 0.4111\n",
      "Epoch 1658/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2536 - val_loss: 0.4114\n",
      "Epoch 1659/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2468 - val_loss: 0.4116\n",
      "Epoch 1660/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2602 - val_loss: 0.4115\n",
      "Epoch 1661/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2691 - val_loss: 0.4117\n",
      "Epoch 1662/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2503 - val_loss: 0.4115\n",
      "Epoch 1663/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2963 - val_loss: 0.4115\n",
      "Epoch 1664/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2819 - val_loss: 0.4116\n",
      "Epoch 1665/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2949 - val_loss: 0.4118\n",
      "Epoch 1666/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2918 - val_loss: 0.4119\n",
      "Epoch 1667/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2682 - val_loss: 0.4120\n",
      "Epoch 1668/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2721 - val_loss: 0.4118\n",
      "Epoch 1669/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2942 - val_loss: 0.4119\n",
      "Epoch 1670/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2691 - val_loss: 0.4119\n",
      "Epoch 1671/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2634 - val_loss: 0.4119\n",
      "Epoch 1672/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3054 - val_loss: 0.4120\n",
      "Epoch 1673/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3089 - val_loss: 0.4121\n",
      "Epoch 1674/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2756 - val_loss: 0.4119\n",
      "Epoch 1675/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2703 - val_loss: 0.4118\n",
      "Epoch 1676/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2694 - val_loss: 0.4121\n",
      "Epoch 1677/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2981 - val_loss: 0.4121\n",
      "Epoch 1678/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2498 - val_loss: 0.4121\n",
      "Epoch 1679/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3101 - val_loss: 0.4123\n",
      "Epoch 1680/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2720 - val_loss: 0.4122\n",
      "Epoch 1681/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2616 - val_loss: 0.4121\n",
      "Epoch 1682/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2833 - val_loss: 0.4118\n",
      "Epoch 1683/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2750 - val_loss: 0.4121\n",
      "Epoch 1684/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2700 - val_loss: 0.4122\n",
      "Epoch 1685/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2799 - val_loss: 0.4124\n",
      "Epoch 1686/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2664 - val_loss: 0.4125\n",
      "Epoch 1687/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2776 - val_loss: 0.4127\n",
      "Epoch 1688/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2730 - val_loss: 0.4126\n",
      "Epoch 1689/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2926 - val_loss: 0.4125\n",
      "Epoch 1690/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2856 - val_loss: 0.4125\n",
      "Epoch 1691/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2644 - val_loss: 0.4124\n",
      "Epoch 1692/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2511 - val_loss: 0.4124\n",
      "Epoch 1693/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2654 - val_loss: 0.4123\n",
      "Epoch 1694/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2421 - val_loss: 0.4123\n",
      "Epoch 1695/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2721 - val_loss: 0.4124\n",
      "Epoch 1696/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2891 - val_loss: 0.4123\n",
      "Epoch 1697/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3118 - val_loss: 0.4122\n",
      "Epoch 1698/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2838 - val_loss: 0.4122\n",
      "Epoch 1699/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2998 - val_loss: 0.4123\n",
      "Epoch 1700/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2886 - val_loss: 0.4123\n",
      "Epoch 1701/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2569 - val_loss: 0.4124\n",
      "Epoch 1702/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2926 - val_loss: 0.4126\n",
      "Epoch 1703/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2542 - val_loss: 0.4128\n",
      "Epoch 1704/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3019 - val_loss: 0.4126\n",
      "Epoch 1705/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2878 - val_loss: 0.4126\n",
      "Epoch 1706/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2737 - val_loss: 0.4127\n",
      "Epoch 1707/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2572 - val_loss: 0.4124\n",
      "Epoch 1708/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2866 - val_loss: 0.4122\n",
      "Epoch 1709/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2486 - val_loss: 0.4122\n",
      "Epoch 1710/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2692 - val_loss: 0.4123\n",
      "Epoch 1711/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2662 - val_loss: 0.4121\n",
      "Epoch 1712/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3312 - val_loss: 0.4118\n",
      "Epoch 1713/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2912 - val_loss: 0.4118\n",
      "Epoch 1714/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2948 - val_loss: 0.4120\n",
      "Epoch 1715/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2873 - val_loss: 0.4121\n",
      "Epoch 1716/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2912 - val_loss: 0.4121\n",
      "Epoch 1717/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2543 - val_loss: 0.4121\n",
      "Epoch 1718/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2696 - val_loss: 0.4123\n",
      "Epoch 1719/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3035 - val_loss: 0.4120\n",
      "Epoch 1720/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2808 - val_loss: 0.4121\n",
      "Epoch 1721/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2651 - val_loss: 0.4123\n",
      "Epoch 1722/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2780 - val_loss: 0.4124\n",
      "Epoch 1723/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2929 - val_loss: 0.4122\n",
      "Epoch 1724/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2863 - val_loss: 0.4122\n",
      "Epoch 1725/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.4125\n",
      "Epoch 1726/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2620 - val_loss: 0.4124\n",
      "Epoch 1727/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2921 - val_loss: 0.4123\n",
      "Epoch 1728/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2812 - val_loss: 0.4124\n",
      "Epoch 1729/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2763 - val_loss: 0.4120\n",
      "Epoch 1730/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2508 - val_loss: 0.4121\n",
      "Epoch 1731/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2678 - val_loss: 0.4122\n",
      "Epoch 1732/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2499 - val_loss: 0.4121\n",
      "Epoch 1733/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2915 - val_loss: 0.4122\n",
      "Epoch 1734/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2643 - val_loss: 0.4122\n",
      "Epoch 1735/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2926 - val_loss: 0.4119\n",
      "Epoch 1736/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2637 - val_loss: 0.4118\n",
      "Epoch 1737/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3166 - val_loss: 0.4113\n",
      "Epoch 1738/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2868 - val_loss: 0.4117\n",
      "Epoch 1739/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2471 - val_loss: 0.4117\n",
      "Epoch 1740/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2418 - val_loss: 0.4117\n",
      "Epoch 1741/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2519 - val_loss: 0.4117\n",
      "Epoch 1742/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2679 - val_loss: 0.4116\n",
      "Epoch 1743/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.4115\n",
      "Epoch 1744/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2657 - val_loss: 0.4116\n",
      "Epoch 1745/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2761 - val_loss: 0.4117\n",
      "Epoch 1746/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2452 - val_loss: 0.4118\n",
      "Epoch 1747/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2660 - val_loss: 0.4119\n",
      "Epoch 1748/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2620 - val_loss: 0.4119\n",
      "Epoch 1749/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2682 - val_loss: 0.4118\n",
      "Epoch 1750/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2646 - val_loss: 0.4118\n",
      "Epoch 1751/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2673 - val_loss: 0.4116\n",
      "Epoch 1752/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2934 - val_loss: 0.4111\n",
      "Epoch 1753/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2584 - val_loss: 0.4113\n",
      "Epoch 1754/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3035 - val_loss: 0.4114\n",
      "Epoch 1755/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2922 - val_loss: 0.4113\n",
      "Epoch 1756/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3117 - val_loss: 0.4111\n",
      "Epoch 1757/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2904 - val_loss: 0.4113\n",
      "Epoch 1758/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2309 - val_loss: 0.4115\n",
      "Epoch 1759/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2753 - val_loss: 0.4114\n",
      "Epoch 1760/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3070 - val_loss: 0.4115\n",
      "Epoch 1761/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2621 - val_loss: 0.4115\n",
      "Epoch 1762/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3263 - val_loss: 0.4118\n",
      "Epoch 1763/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2450 - val_loss: 0.4119\n",
      "Epoch 1764/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.4119\n",
      "Epoch 1765/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2886 - val_loss: 0.4121\n",
      "Epoch 1766/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2648 - val_loss: 0.4120\n",
      "Epoch 1767/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2928 - val_loss: 0.4118\n",
      "Epoch 1768/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2705 - val_loss: 0.4118\n",
      "Epoch 1769/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2695 - val_loss: 0.4114\n",
      "Epoch 1770/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2704 - val_loss: 0.4113\n",
      "Epoch 1771/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2710 - val_loss: 0.4115\n",
      "Epoch 1772/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2462 - val_loss: 0.4118\n",
      "Epoch 1773/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2790 - val_loss: 0.4117\n",
      "Epoch 1774/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2739 - val_loss: 0.4118\n",
      "Epoch 1775/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2896 - val_loss: 0.4118\n",
      "Epoch 1776/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2776 - val_loss: 0.4119\n",
      "Epoch 1777/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2703 - val_loss: 0.4118\n",
      "Epoch 1778/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2508 - val_loss: 0.4120\n",
      "Epoch 1779/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3045 - val_loss: 0.4121\n",
      "Epoch 1780/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2774 - val_loss: 0.4123\n",
      "Epoch 1781/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2650 - val_loss: 0.4121\n",
      "Epoch 1782/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2414 - val_loss: 0.4120\n",
      "Epoch 1783/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2697 - val_loss: 0.4120\n",
      "Epoch 1784/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2318 - val_loss: 0.4121\n",
      "Epoch 1785/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2611 - val_loss: 0.4124\n",
      "Epoch 1786/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2785 - val_loss: 0.4123\n",
      "Epoch 1787/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2888 - val_loss: 0.4122\n",
      "Epoch 1788/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3164 - val_loss: 0.4123\n",
      "Epoch 1789/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2553 - val_loss: 0.4124\n",
      "Epoch 1790/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2677 - val_loss: 0.4125\n",
      "Epoch 1791/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2957 - val_loss: 0.4127\n",
      "Epoch 1792/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2943 - val_loss: 0.4127\n",
      "Epoch 1793/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2705 - val_loss: 0.4128\n",
      "Epoch 1794/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2531 - val_loss: 0.4129\n",
      "Epoch 1795/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2759 - val_loss: 0.4129\n",
      "Epoch 1796/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2373 - val_loss: 0.4127\n",
      "Epoch 1797/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3180 - val_loss: 0.4126\n",
      "Epoch 1798/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2880 - val_loss: 0.4126\n",
      "Epoch 1799/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2694 - val_loss: 0.4126\n",
      "Epoch 1800/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2989 - val_loss: 0.4124\n",
      "Epoch 1801/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2789 - val_loss: 0.4120\n",
      "Epoch 1802/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2694 - val_loss: 0.4124\n",
      "Epoch 1803/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2819 - val_loss: 0.4124\n",
      "Epoch 1804/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2803 - val_loss: 0.4127\n",
      "Epoch 1805/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2716 - val_loss: 0.4131\n",
      "Epoch 1806/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3043 - val_loss: 0.4131\n",
      "Epoch 1807/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2540 - val_loss: 0.4131\n",
      "Epoch 1808/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2713 - val_loss: 0.4130\n",
      "Epoch 1809/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2630 - val_loss: 0.4128\n",
      "Epoch 1810/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2826 - val_loss: 0.4131\n",
      "Epoch 1811/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2895 - val_loss: 0.4131\n",
      "Epoch 1812/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2549 - val_loss: 0.4129\n",
      "Epoch 1813/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2743 - val_loss: 0.4132\n",
      "Epoch 1814/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3024 - val_loss: 0.4133\n",
      "Epoch 1815/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3095 - val_loss: 0.4135\n",
      "Epoch 1816/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2905 - val_loss: 0.4133\n",
      "Epoch 1817/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2811 - val_loss: 0.4135\n",
      "Epoch 1818/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2569 - val_loss: 0.4134\n",
      "Epoch 1819/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2990 - val_loss: 0.4132\n",
      "Epoch 1820/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2700 - val_loss: 0.4131\n",
      "Epoch 1821/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2617 - val_loss: 0.4133\n",
      "Epoch 1822/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2524 - val_loss: 0.4131\n",
      "Epoch 1823/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2606 - val_loss: 0.4132\n",
      "Epoch 1824/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2586 - val_loss: 0.4131\n",
      "Epoch 1825/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2785 - val_loss: 0.4127\n",
      "Epoch 1826/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2845 - val_loss: 0.4127\n",
      "Epoch 1827/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2587 - val_loss: 0.4122\n",
      "Epoch 1828/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2682 - val_loss: 0.4121\n",
      "Epoch 1829/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2777 - val_loss: 0.4119\n",
      "Epoch 1830/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2705 - val_loss: 0.4120\n",
      "Epoch 1831/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2671 - val_loss: 0.4122\n",
      "Epoch 1832/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2633 - val_loss: 0.4122\n",
      "Epoch 1833/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3027 - val_loss: 0.4121\n",
      "Epoch 1834/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2696 - val_loss: 0.4121\n",
      "Epoch 1835/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2570 - val_loss: 0.4120\n",
      "Epoch 1836/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2849 - val_loss: 0.4120\n",
      "Epoch 1837/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2699 - val_loss: 0.4121\n",
      "Epoch 1838/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3012 - val_loss: 0.4122\n",
      "Epoch 1839/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2879 - val_loss: 0.4121\n",
      "Epoch 1840/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2748 - val_loss: 0.4122\n",
      "Epoch 1841/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2922 - val_loss: 0.4119\n",
      "Epoch 1842/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2919 - val_loss: 0.4122\n",
      "Epoch 1843/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2861 - val_loss: 0.4121\n",
      "Epoch 1844/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2702 - val_loss: 0.4123\n",
      "Epoch 1845/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3186 - val_loss: 0.4124\n",
      "Epoch 1846/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3105 - val_loss: 0.4128\n",
      "Epoch 1847/2000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2548 - val_loss: 0.4129\n",
      "Epoch 1848/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2753 - val_loss: 0.4128\n",
      "Epoch 1849/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2803 - val_loss: 0.4129\n",
      "Epoch 1850/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2459 - val_loss: 0.4128\n",
      "Epoch 1851/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.4126\n",
      "Epoch 1852/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2758 - val_loss: 0.4127\n",
      "Epoch 1853/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2740 - val_loss: 0.4127\n",
      "Epoch 1854/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2822 - val_loss: 0.4126\n",
      "Epoch 1855/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2716 - val_loss: 0.4126\n",
      "Epoch 1856/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3405 - val_loss: 0.4123\n",
      "Epoch 1857/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3013 - val_loss: 0.4122\n",
      "Epoch 1858/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.4124\n",
      "Epoch 1859/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2941 - val_loss: 0.4121\n",
      "Epoch 1860/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2438 - val_loss: 0.4122\n",
      "Epoch 1861/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3151 - val_loss: 0.4121\n",
      "Epoch 1862/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2644 - val_loss: 0.4121\n",
      "Epoch 1863/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2624 - val_loss: 0.4121\n",
      "Epoch 1864/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2683 - val_loss: 0.4122\n",
      "Epoch 1865/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2462 - val_loss: 0.4121\n",
      "Epoch 1866/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2917 - val_loss: 0.4119\n",
      "Epoch 1867/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2732 - val_loss: 0.4121\n",
      "Epoch 1868/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2767 - val_loss: 0.4117\n",
      "Epoch 1869/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2859 - val_loss: 0.4116\n",
      "Epoch 1870/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2619 - val_loss: 0.4114\n",
      "Epoch 1871/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2768 - val_loss: 0.4114\n",
      "Epoch 1872/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2619 - val_loss: 0.4118\n",
      "Epoch 1873/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2929 - val_loss: 0.4118\n",
      "Epoch 1874/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2476 - val_loss: 0.4118\n",
      "Epoch 1875/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2902 - val_loss: 0.4116\n",
      "Epoch 1876/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3041 - val_loss: 0.4118\n",
      "Epoch 1877/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2641 - val_loss: 0.4117\n",
      "Epoch 1878/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2871 - val_loss: 0.4115\n",
      "Epoch 1879/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2847 - val_loss: 0.4115\n",
      "Epoch 1880/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2995 - val_loss: 0.4116\n",
      "Epoch 1881/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3187 - val_loss: 0.4111\n",
      "Epoch 1882/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2724 - val_loss: 0.4110\n",
      "Epoch 1883/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3047 - val_loss: 0.4111\n",
      "Epoch 1884/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2931 - val_loss: 0.4111\n",
      "Epoch 1885/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3246 - val_loss: 0.4110\n",
      "Epoch 1886/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2675 - val_loss: 0.4113\n",
      "Epoch 1887/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2726 - val_loss: 0.4114\n",
      "Epoch 1888/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2891 - val_loss: 0.4113\n",
      "Epoch 1889/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3177 - val_loss: 0.4108\n",
      "Epoch 1890/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2831 - val_loss: 0.4106\n",
      "Epoch 1891/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3137 - val_loss: 0.4107\n",
      "Epoch 1892/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2748 - val_loss: 0.4107\n",
      "Epoch 1893/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2461 - val_loss: 0.4107\n",
      "Epoch 1894/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3079 - val_loss: 0.4109\n",
      "Epoch 1895/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2614 - val_loss: 0.4109\n",
      "Epoch 1896/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2891 - val_loss: 0.4109\n",
      "Epoch 1897/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2494 - val_loss: 0.4107\n",
      "Epoch 1898/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2726 - val_loss: 0.4108\n",
      "Epoch 1899/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2992 - val_loss: 0.4112\n",
      "Epoch 1900/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3010 - val_loss: 0.4113\n",
      "Epoch 1901/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2640 - val_loss: 0.4115\n",
      "Epoch 1902/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2749 - val_loss: 0.4116\n",
      "Epoch 1903/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2697 - val_loss: 0.4116\n",
      "Epoch 1904/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2961 - val_loss: 0.4116\n",
      "Epoch 1905/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3033 - val_loss: 0.4117\n",
      "Epoch 1906/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3108 - val_loss: 0.4114\n",
      "Epoch 1907/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2735 - val_loss: 0.4115\n",
      "Epoch 1908/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2606 - val_loss: 0.4115\n",
      "Epoch 1909/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2717 - val_loss: 0.4113\n",
      "Epoch 1910/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2743 - val_loss: 0.4112\n",
      "Epoch 1911/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2872 - val_loss: 0.4113\n",
      "Epoch 1912/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2785 - val_loss: 0.4110\n",
      "Epoch 1913/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2777 - val_loss: 0.4112\n",
      "Epoch 1914/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2732 - val_loss: 0.4111\n",
      "Epoch 1915/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2703 - val_loss: 0.4114\n",
      "Epoch 1916/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2585 - val_loss: 0.4116\n",
      "Epoch 1917/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2872 - val_loss: 0.4114\n",
      "Epoch 1918/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2665 - val_loss: 0.4112\n",
      "Epoch 1919/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2730 - val_loss: 0.4110\n",
      "Epoch 1920/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2727 - val_loss: 0.4110\n",
      "Epoch 1921/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2659 - val_loss: 0.4110\n",
      "Epoch 1922/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2567 - val_loss: 0.4110\n",
      "Epoch 1923/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2946 - val_loss: 0.4113\n",
      "Epoch 1924/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2582 - val_loss: 0.4113\n",
      "Epoch 1925/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2937 - val_loss: 0.4113\n",
      "Epoch 1926/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2546 - val_loss: 0.4115\n",
      "Epoch 1927/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2753 - val_loss: 0.4116\n",
      "Epoch 1928/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2688 - val_loss: 0.4114\n",
      "Epoch 1929/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2988 - val_loss: 0.4118\n",
      "Epoch 1930/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2823 - val_loss: 0.4118\n",
      "Epoch 1931/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3061 - val_loss: 0.4120\n",
      "Epoch 1932/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2787 - val_loss: 0.4121\n",
      "Epoch 1933/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2806 - val_loss: 0.4120\n",
      "Epoch 1934/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2773 - val_loss: 0.4118\n",
      "Epoch 1935/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2615 - val_loss: 0.4116\n",
      "Epoch 1936/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2650 - val_loss: 0.4117\n",
      "Epoch 1937/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2884 - val_loss: 0.4117\n",
      "Epoch 1938/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2986 - val_loss: 0.4116\n",
      "Epoch 1939/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2653 - val_loss: 0.4115\n",
      "Epoch 1940/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2856 - val_loss: 0.4116\n",
      "Epoch 1941/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2936 - val_loss: 0.4117\n",
      "Epoch 1942/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3104 - val_loss: 0.4117\n",
      "Epoch 1943/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2421 - val_loss: 0.4120\n",
      "Epoch 1944/2000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2976 - val_loss: 0.4118\n",
      "Epoch 1945/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2601 - val_loss: 0.4119\n",
      "Epoch 1946/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2353 - val_loss: 0.4120\n",
      "Epoch 1947/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2636 - val_loss: 0.4119\n",
      "Epoch 1948/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2663 - val_loss: 0.4121\n",
      "Epoch 1949/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2725 - val_loss: 0.4122\n",
      "Epoch 1950/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2738 - val_loss: 0.4120\n",
      "Epoch 1951/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2963 - val_loss: 0.4118\n",
      "Epoch 1952/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2720 - val_loss: 0.4121\n",
      "Epoch 1953/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2908 - val_loss: 0.4119\n",
      "Epoch 1954/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2797 - val_loss: 0.4118\n",
      "Epoch 1955/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2850 - val_loss: 0.4118\n",
      "Epoch 1956/2000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2773 - val_loss: 0.4118\n",
      "Epoch 1957/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2765 - val_loss: 0.4118\n",
      "Epoch 1958/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2727 - val_loss: 0.4122\n",
      "Epoch 1959/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2576 - val_loss: 0.4117\n",
      "Epoch 1960/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2741 - val_loss: 0.4118\n",
      "Epoch 1961/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2808 - val_loss: 0.4117\n",
      "Epoch 1962/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2906 - val_loss: 0.4118\n",
      "Epoch 1963/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2844 - val_loss: 0.4118\n",
      "Epoch 1964/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3070 - val_loss: 0.4116\n",
      "Epoch 1965/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2907 - val_loss: 0.4119\n",
      "Epoch 1966/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2694 - val_loss: 0.4122\n",
      "Epoch 1967/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2784 - val_loss: 0.4122\n",
      "Epoch 1968/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2649 - val_loss: 0.4124\n",
      "Epoch 1969/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2812 - val_loss: 0.4123\n",
      "Epoch 1970/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2822 - val_loss: 0.4122\n",
      "Epoch 1971/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2715 - val_loss: 0.4123\n",
      "Epoch 1972/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2640 - val_loss: 0.4123\n",
      "Epoch 1973/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3103 - val_loss: 0.4122\n",
      "Epoch 1974/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2648 - val_loss: 0.4123\n",
      "Epoch 1975/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2894 - val_loss: 0.4125\n",
      "Epoch 1976/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2705 - val_loss: 0.4127\n",
      "Epoch 1977/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2941 - val_loss: 0.4130\n",
      "Epoch 1978/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3050 - val_loss: 0.4129\n",
      "Epoch 1979/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2861 - val_loss: 0.4127\n",
      "Epoch 1980/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2628 - val_loss: 0.4126\n",
      "Epoch 1981/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2607 - val_loss: 0.4127\n",
      "Epoch 1982/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2753 - val_loss: 0.4126\n",
      "Epoch 1983/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2552 - val_loss: 0.4125\n",
      "Epoch 1984/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2578 - val_loss: 0.4122\n",
      "Epoch 1985/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2723 - val_loss: 0.4125\n",
      "Epoch 1986/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2504 - val_loss: 0.4125\n",
      "Epoch 1987/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2788 - val_loss: 0.4129\n",
      "Epoch 1988/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2892 - val_loss: 0.4130\n",
      "Epoch 1989/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2647 - val_loss: 0.4128\n",
      "Epoch 1990/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3008 - val_loss: 0.4128\n",
      "Epoch 1991/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2787 - val_loss: 0.4130\n",
      "Epoch 1992/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2698 - val_loss: 0.4131\n",
      "Epoch 1993/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2834 - val_loss: 0.4133\n",
      "Epoch 1994/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2580 - val_loss: 0.4134\n",
      "Epoch 1995/2000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2597 - val_loss: 0.4135\n",
      "Epoch 1996/2000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2945 - val_loss: 0.4133\n",
      "Epoch 1997/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2562 - val_loss: 0.4131\n",
      "Epoch 1998/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2718 - val_loss: 0.4135\n",
      "Epoch 1999/2000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2636 - val_loss: 0.4138\n",
      "Epoch 2000/2000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2782 - val_loss: 0.4138\n"
     ]
    }
   ],
   "source": [
    "# Define the input layer\n",
    "inputs = tf.keras.Input(shape=(Xtrain.shape[1]))\n",
    "\n",
    "# Define the hidden layers\n",
    "hidden = tf.keras.layers.Dense(\n",
    "    16, \n",
    "    activation='relu', \n",
    "    kernel_initializer=tf.keras.initializers.he_normal(seed=1),\n",
    "    bias_initializer='zeros', \n",
    "    kernel_regularizer=tf.keras.regularizers.L2(0.01))(inputs)\n",
    "hidden = tf.keras.layers.BatchNormalization()(hidden)\n",
    "hidden = tf.keras.layers.Dense(\n",
    "    32, activation='relu', \n",
    "    kernel_initializer=tf.keras.initializers.he_normal(seed=1),\n",
    "    bias_initializer='zeros', \n",
    "    kernel_regularizer=tf.keras.regularizers.L2(0.01))(hidden)\n",
    "hidden = tf.keras.layers.BatchNormalization()(hidden)\n",
    "hidden = tf.keras.layers.Dense(\n",
    "    16, \n",
    "    activation='relu', \n",
    "    kernel_initializer=tf.keras.initializers.he_normal(seed=1),\n",
    "    bias_initializer='zeros', \n",
    "    kernel_regularizer=tf.keras.regularizers.L2(0.01))(hidden)\n",
    "hidden = tf.keras.layers.BatchNormalization()(hidden)\n",
    "\n",
    "# Define the output layer. Make sure the output dimension is correct.\n",
    "outputs = tf.keras.layers.Dense(1, activation='relu')(hidden) # Ensures output is non-negative\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "#Define the learning rate schedule\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.01,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.92,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "\n",
    "# Define a custom callback function\n",
    "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['val_loss'] <0.12 and logs['loss']<0.12:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "custom_early_stopping = CustomEarlyStopping()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer= opt, \n",
    "    loss='mean_absolute_error'\n",
    "#    metrics=['accuracy']\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint('model.h5', \n",
    "                                   monitor='val_loss', \n",
    "                                   save_best_only=True)\n",
    "# Train your model\n",
    "history = model.fit(\n",
    "    Xtrain,\n",
    "    Ytrain,\n",
    "    batch_size=64,\n",
    "    epochs=2000,\n",
    "    validation_data=(Xtest, Ytest),\n",
    "    callbacks=[custom_early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187b9e7",
   "metadata": {},
   "source": [
    "### Evaluating model performance on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650f4699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "R-squared for train: 0.93\n",
      "R-squared for test: 0.84\n",
      "MAE for train: 0.16\n",
      "MAE for test: 0.38\n",
      "Median Absolute Error for train: 0.08\n",
      "Median Absolute Error for test: 0.29\n",
      "Normalized Root Mean Square Error for train: 29.95\n",
      "Normalized Root Mean Square Error for test: 56.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "Ytrain_pred = model.predict(Xtrain)\n",
    "Ytest_pred = model.predict(Xtest)\n",
    "\n",
    "\n",
    "print(\"R-squared for train: {:.2f}\".format(r2_score(Ytrain, Ytrain_pred)))\n",
    "print(\"R-squared for test: {:.2f}\".format(r2_score(Ytest, Ytest_pred)))\n",
    "print(\"MAE for train: {:.2f}\".format(metrics.mean_absolute_error(Ytrain, Ytrain_pred)))\n",
    "print(\"MAE for test: {:.2f}\".format(metrics.mean_absolute_error(Ytest, Ytest_pred)))\n",
    "print(\"Median Absolute Error for train: {:.2f}\".format(median_absolute_error(Ytrain, Ytrain_pred)))\n",
    "print(\"Median Absolute Error for test: {:.2f}\".format(median_absolute_error(Ytest, Ytest_pred)))\n",
    "print(\"Normalized Root Mean Square Error for train: {:.2f}\".format(np.sqrt(mean_squared_error(Ytrain, Ytrain_pred))*100 / (np.mean(Ytrain))))\n",
    "print(\"Normalized Root Mean Square Error for test: {:.2f}\".format(np.sqrt(mean_squared_error(Ytest, Ytest_pred))*100 / (np.mean(Ytest))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c8fe0",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aafdcdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Scenario2.h5\n"
     ]
    }
   ],
   "source": [
    "# Specify the path and filename for the model\n",
    "model_path = 'Scenario2.h5'\n",
    "\n",
    "# Use the .save() method to save your model\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c910d7c",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896ac2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Scatter plot for simulated vs observed max flood depths (Train Data)\n",
    "axes[0].scatter(Ytrain, Ytrain_pred, color='blue', label='Train Data')\n",
    "axes[0].plot([Ytrain.min(), Ytrain.max()], [Ytrain.min(), Ytrain.max()], 'k--', lw=2, label='Identity Line')\n",
    "axes[0].set_xlabel('Observed maximum water depths (m)', fontweight='bold')\n",
    "axes[0].set_ylabel('Estimated maximum water depths (m)', fontweight='bold')\n",
    "axes[0].set_title('(a)')\n",
    "axes[0].legend(frameon=False)  # No legend box\n",
    "\n",
    "# Scatter plot for simulated vs observed max flood depths (Test Data)\n",
    "axes[1].scatter(Ytest, Ytest_pred, color='blue', label='Test Data')\n",
    "axes[1].plot([Ytest.min(), Ytest.max()], [Ytest.min(), Ytest.max()], 'k--', lw=2, label='Identity Line')\n",
    "axes[1].set_xlabel('Observed maximum water depths (m)', fontweight='bold')\n",
    "axes[1].set_ylabel('Estimated maximum water depths (m)', fontweight='bold')\n",
    "axes[1].set_title('(b)')\n",
    "axes[1].legend(frameon=False)  # No legend box\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4125ca5",
   "metadata": {},
   "source": [
    "### Evaluating stream gauges, HWMs, and stream gagues + HWMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae672a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_model(predictions, actuals, model_name):\n",
    "    # Flatten predictions if necessary\n",
    "    predictions = predictions\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r_squared = np.round(r2_score(actuals, predictions), 2)\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    mdae = median_absolute_error(actuals, predictions)\n",
    "    nrmse = np.sqrt(mean_squared_error(actuals, predictions)) * 100 / np.mean(actuals)\n",
    "    bias = np.mean(predictions - actuals)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    \n",
    "    # Prepare DataFrame\n",
    "    errors_df = pd.DataFrame({\n",
    "        \"Metric\": [\"R-squared\", \"MAE\", \"Median Absolute Error\", \"NRMSE\", \"BIAS\", \"RMSE\"],\n",
    "        \"Value\": [r_squared, mae, mdae, nrmse, bias, rmse]\n",
    "    })\n",
    "    \n",
    "    # Print the DataFrame to check\n",
    "    print(f\"Errors for {model_name}:\")\n",
    "    print(errors_df)\n",
    "\n",
    "    # Save to CSV\n",
    "    errors_df.to_csv(f\"errors_{model_name}.csv\", index=False)\n",
    "\n",
    "    return errors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e501d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step\n",
      "Errors for Overall_S2:\n",
      "                  Metric      Value\n",
      "0              R-squared   0.910000\n",
      "1                    MAE   0.205335\n",
      "2  Median Absolute Error   0.097246\n",
      "3                  NRMSE  36.388751\n",
      "4                   BIAS  -0.035501\n",
      "5                   RMSE   0.352105\n",
      "Errors for Stream_S2:\n",
      "                  Metric      Value\n",
      "0              R-squared   0.920000\n",
      "1                    MAE   0.242144\n",
      "2  Median Absolute Error   0.078918\n",
      "3                  NRMSE  22.596293\n",
      "4                   BIAS  -0.070590\n",
      "5                   RMSE   0.443617\n",
      "Errors for HWMs_S2:\n",
      "                  Metric      Value\n",
      "0              R-squared   0.600000\n",
      "1                    MAE   0.188591\n",
      "2  Median Absolute Error   0.104417\n",
      "3                  NRMSE  58.559995\n",
      "4                   BIAS  -0.019538\n",
      "5                   RMSE   0.301419\n"
     ]
    }
   ],
   "source": [
    "# Conversion factor from some unit to meters, assuming 'Flood' is initially in some other units\n",
    "y_t = df['Flood'] * 0.3048 \n",
    "\n",
    "# Ensure 'features' contains the correct column names you want to use for the model\n",
    "x_t = df[features].copy()\n",
    "\n",
    "# Scale the data\n",
    "x_t_scaled = scaler.fit_transform(x_t)\n",
    "\n",
    "# Assuming 'best_model' is already trained and ready to be used for predictions\n",
    "y_t_pred = model.predict(x_t_scaled).flatten()\n",
    "\n",
    "\n",
    "errors_df_t = evaluate_model(y_t_pred, y_t, \"Overall_S2\")\n",
    "\n",
    "\n",
    "# First, add y_t and y_t_pred to your DataFrame if they aren't already included\n",
    "df['y_t'] = y_t\n",
    "df['y_t_pred'] = y_t_pred\n",
    "\n",
    "\n",
    "\n",
    "# Correct filtering of the DataFrame based on 'Type'\n",
    "df_strm = df[df['Type'] == 'Stream']\n",
    "\n",
    "# Conversion factor from some unit to meters, assuming 'Flood' is initially in some other units\n",
    "y_strm = df_strm['y_t']  \n",
    "y_strm_pred = df_strm['y_t_pred'] \n",
    "\n",
    "errors_df_strm = evaluate_model(y_strm_pred, y_strm, \"Stream_S2\")\n",
    "\n",
    "\n",
    "# Correct filtering of the DataFrame based on 'Type'\n",
    "df_HWM = df[df['Type'] == 'HWMs']\n",
    "\n",
    "# Conversion factor from some unit to meters, assuming 'Flood' is initially in some other units\n",
    "y_HWM = df_HWM['y_t']  \n",
    "y_HWM_pred = df_HWM['y_t_pred'] \n",
    "\n",
    "errors_df_HWM = evaluate_model(y_HWM_pred, y_HWM, \"HWMs_S2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
